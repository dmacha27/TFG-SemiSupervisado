\apendice{Plan de Proyecto Software}

\section{Introducción}

En el presente apartado de los anexos se analizará la gestión del proyecto
software desarrollado. Este proyecto será organizado mediante la metodología
Scrum en la que el trabajo estará dividido en Sprints. Por cada Sprint se
realiza una reunión para la revisión del avance y los objetivos para el
siguiente.  Con esta metodología se mantendrá en todo momento lo que se conoce
como \textit{Product Backlog} que es una lista de las tareas a realizar. Esta
lista será actualizada en cada reunión para mantener un desarrollo constante.

Las reuniones, en un principio, se realizan cada dos semanas, intensificando a
cada semana en el momento del inicio del periodo temporal del segundo
cuatrimestre.

Finalmente también se incluirá un análisis de la viabilidad económica y legal
(ámbito de licencias software).

El objetivo de este plan es servir como herramienta para registrar el avance del
proyecto y también para poder cumplir con el objetivo final del desarrollo.

\section{Planificación temporal}
La planificación temporal se comenzó mediante Sprints de dos semanas. En la
presente sección se comentará el desarrollo realizado en cada uno de ellos.

\subsection{Sprint 0}

Desde el punto de vista temporal, corresponde desde el inicio del curso del
primer cuatrimestre académico (septiembre) hasta el Sprint 1. El día 15 de
septiembre se tuvo la primera reunión con los tutores sobre el trabajo presente
donde se establecieron las líneas generales y temática sobre el mismo.

Se creó el repositorio del TFG en Github:
\url{https://github.com/dma1004/TFG-SemiSupervisado} y se añadió la plantilla de
la documentación.

\subsection{Sprint 1}

Corresponde con el periodo temporal del 5 al 19 de octubre de 2022. 

El mismo día 5 tuvo lugar una reunión de seguimiento del trabajo. Durante el sprint se
realizaron unos arreglos de la plantilla y una lectura de conceptos teóricos
para posteriormente añadirlos a la documentación. Concretamente se crearon las
tareas "<Añadir conceptos teóricos aprendizaje"> y "<Trabajos relacionados"> a
día 9 de octubre.

\subsection{Sprint 2}

Corresponde con el periodo temporal del 19 de octubre al 2 de noviembre de 2022. 

Durante el sprint se implementó un prototipo del algoritmo Self-Training en el
que posteriormente se hicieron unas correcciones en el código. También se
comenzó con la redacción de conceptos teóricos, concretamente, sobre el
aprendizaje automático.

\subsection{Sprint 3}

Corresponde con el periodo temporal del 16 al 30 de noviembre de 2022.

Durante el sprint se aumentaron los conceptos teóricos sobre el aprendizaje
supervisado, no supervisado y semi-supervisado. Se refactorizó el prototipo para
su documentación (PEP), evitar datos duplicados y modularizar el código.

La memoria fue parcialmente modificada basándose en las correcciones propuestas
de los tutores.

\subsection{Sprint 4}

Corresponde con el periodo temporal del 25 de enero al 1 de febrero de 2023. En
este momento las duraciones de los Sprints cambiaron a una semana, iniciando así
el periodo temporal real del desarrollo del proyecto (segundo cuatrimestre).

Durante el sprint se retomaron las tareas y el desarrollo general del proyecto.
Se mejoró el algoritmo de \texttt{SelfTraining} que estaba como prototipo y se
avanzó en la tarea de la primera aproximación en la aplicación mediante el
\textit{framework} Flask. Sobre esto último, se creó una visualización del
proceso de entrenamiento muy básica por cada iteración.

Se creó un prototipo del algoritmo \texttt{CoTraining} sin cumplir con todas sus
condiciones que posteriormente se completaron a falta de revisión. 

Sobre estos dos algoritmos se propuso la versión 1.0. 

Continuando con la Web, se realizó la interfaz general funcional. Incluye:
\begin{itemize}
    \item Página de Inicio donde seleccionar el algoritmo.
    \item Página de subida de archivos en formatos <<ARFF>> y <<CSV>> de los
    conjuntos de datos
    \item Páginas correspondientes para SelfTraining y CoTraining: Cada una
    tiene sus parámetros específicos con la posibilidad de seleccionar si
    utilizar PCA (\textit{Principal Component Analysis}) o dos componentes que
    elija el usuario.
    \item Página de visualización del algoritmo (su entrenamiento): Se tiene la
    vista principal que será común a todos los algoritmos (con algunas
    variaciones en caso necesario), con la posibilidad de avanzar en la
    visualización (con controles) y barra de progreso. Desde el punto de vista
    del gráfico los colores están automatizados dependiendo del número de
    clases, leyenda y etiqueta de ejes.
\end{itemize}

En Flask se añadieron los <<endpoints>> correspondientes (subida, configuración,
visualización...) y un control de acceso a las páginas muy básico (por ejemplo,
si no se configuró el algoritmo, no se puede visualizar y le redirecciona a la
configuración con un mensaje de error)

\subsection{Sprint 5}
Corresponde con el periodo temporal del 1 al 8 de febrero de 2023.

En la reunión del 1 de febrero se revisó lo realizado en el anterior y se fijaron
una serie de mejoras/modificaciones y nuevas tareas:
\begin{enumerate}
    \item Modificación de los algoritmos para trabajar con la convención de
    <<-1s>> en el conjunto de datos para los datos no etiquetados. Así el
    usuario podrá subir un archivo ya \textit{Semi-Supervisado}.
    \item Permitir al usuario seleccionar los porcentajes de no etiquetados y de
    test (para las futuras estadísticas).
    \item Sobre la página general de la visualización de los algoritmos: volver
    a la configuración, el <<feedback>> de la iteración actual y el nombre del
    conjunto de datos utilizado.
    \item Del gráfico de la visualización: Diferenciar en el algoritmo
    Co-Training cuál de los dos clasificadores han etiquetado cada punto y los
    puntos <<etiquetados>> en la iteración 0 deben mostrarse de forma diferente.
    \item Avanzar con los trabajos relacionados.
    \item Avanzar con la documentación teórica y anexos.
\end{enumerate}

El punto 1 ha llevado unas 12 horas de compresión y desarrollo. Esto es debido a
que los dos algoritmos implementados hasta ahora debían ser modificados para
trabajar con la nueva convención. Además, el problema principal fue (aunque no
implementado en este Sprint) dejar preparada una forma de carga del conjunto de
datos que permita tratar datos no etiquetados (los <<?>> en el caso de ARFF),
pues además de los algoritmos (su correcto funcionamiento), se han probado con
ficheros. También conllevó la creación de un codificador de etiquetas propio
para ignorar los no etiquetados en clases categóricas (y no realizar la
conversión en esos casos).

El punto 2 volvió a causar bastantes problemas tanto en la ejecución de los
algoritmos como en la Web. Hasta el momento, el usuario no seleccionaba los
porcentajes de las divisiones, pero al incluir esto, los algoritmos ya no se
encargan de esta tarea y había que modificar tanto los algoritmos como aquellas
rutas de la Web que debían encargarse de esto. Aproximadamente 4 horas.

El punto 3 no resultó demasiado difícil más allá de seguir habituándose a
JavaScript/HTML. Unas 3 horas.

El punto 4 requirió unas 10 horas, en un principio se perdió mucho tiempo
intentando solucionarlo de una forma que resultó inútil, pero finalmente ahora
en el algoritmo se diferencian los datos clasificados por cada uno.

Los trabajos relacionados (no terminados) se realizaron en varios días con un
tiempo aproximado de 6 horas.

\subsection{Sprint 6}
Corresponde con el periodo temporal del 8 al 15 de febrero de 2023.

En la reunión del 8 de febrero se revisó lo realizado en el anterior y se
comentaron algunas tareas a realizar:
\begin{enumerate}
    \item En la línea del anterior, los algoritmos deben poder ejecutarse
    directamente con conjuntos de datos semi-supervisados.
    \item Permitir al usuario introducir ese tipo de conjuntos de datos.
    \item Realizar alguna visualización de estadísticas.
    \item Valor por defecto en las configuraciones.
    \item Sobre el gráfico: mejorar la diferenciación de los puntos, información
    útil en los <<tooltips>> y colocación de la leyenda.
    \item Avanzar con los trabajos relacionados.
    \item Avanzar con la memoria y anexos.
\end{enumerate}

Los puntos 1 y 2 estaban muy avanzados gracias al trabajo adicional del sprint
anterior, ya que estaba prácticamente implementada la forma en la que detectar
datos no etiquetados de forma automática. Unas 5 horas para terminar de
implementar, corregir errores sobre la marcha y realizar alguna prueba
confeccionando ficheros semi-supervisados.

Al realizar las pruebas anteriores se encontró un error en la visualización
provocando que los datos que los datos no se habían clasificado ni siquiera eran
retornados a la Web. Entre descubrir cómo corregirlo y sus modificaciones se
tardó unas 3 horas.

El punto 3 fue el más complicado, pese a que era una idea sencilla, se optó por
visualizar la gráfica de la evolución de la precisión. Cada punto del gráfico
está unido por una serie de líneas. Este tipo de gráficos (según la
documentación) se suelen hacer mediante <<paths>> o caminos, que son una única
línea, pero como en este caso era necesario no visualizar todo, sino por cada
iteración, no se encontró una solución rápida. Unas 6 horas para probar muchas
posibilidades hasta encontrar la que funcionó, acoplarla a los controles del
paso de iteración e incluir alguna animación.

Adicionalmente se retocó por completo toda la Web mediante los estilos de
\texttt{Bootstrap} para establecer ya una base vistosa y bonita. Unas 5 horas
(la mayor parte del tiempo para probar y adquirir algo de soltura con estos
estilos).

\subsection{Sprint 7}
Corresponde con el periodo temporal del 15 al 22 de febrero de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Implementación Democratic Co-Learning.
    \item Profiling (tiempos de ejecución).
    \item Estadísticas en la aplicación.
    \item Test de las implementaciones.
    \item Avanzar con la memoria y anexos.
\end{enumerate}

La implementación del algoritmo Democratic Co-Learning supuso unas 14 horas
divididas en varios días. Al principio se dedicó un tiempo para leer el artículo
en el que se presentaba su implementación en forma de pseudocódigo junto con sus
explicaciones teóricas. La realidad es que en primera instancia parecía algo
fácil de realizar y entender, pero una vez comenzada la implementación, se
encontraban muchas cuestiones a la hora de resolverlo. 

Además, pese a que en el artículo estaba bien explicado, el formato de
pseudocódigo (en el archivo encontrado) tenía indentaciones incorrectas y se
perdió mucho tiempo comprobando si era una interpretación errónea o si realmente
era un fallo.

Se realizaron algunas pruebas de rendimiento para comprobar si los algoritmos
tardaban demasiado con conjuntos de datos muy grandes (5\,000 instancias). Se
observó que, dada la configuración que se tenía, tardaba alrededor de 40-50
segundos en terminar la ejecución. Es por esto que para este Sprint se añadió la
tarea de hacer un pequeño estudio dedicado a medir los tiempos de ejecución para
ver qué se podía optimizar. 

Este proceso fue de unas 2 horas y el resultado fue que el código implementado
no afectaba mucho, eran los propios algoritmos de entrenamiento de los
clasificadores de Scikit-Learn los que tardaban tanto. Por ejemplo, para un
estimador gaussiano el tiempo se reducía drásticamente.

Para el caso de las estadísticas, se modificaron un poco las plantillas y la
generación de sus gráficas para incluir más y revisarlas en la reunión. Unas 2
horas.

Los tests son una parte importante para validar que el comportamiento que se
espera de la implementación sea el correcto. Se realizaron unos casos de pruebas
sobre las utilidades que se usan a lo largo de todo el proyecto con la intención
de encontrar errores (todo esto sin ver cuál es el resultado y replicarlo en los
casos, sino realizar los casos basándose en lo que se espera de esas
utilidades). Se tardó unas 4 horas en realizar todos los tests.

\subsection{Sprint 8}
Corresponde con el periodo temporal del 22 de febrero al 1 de marzo de 2023.
Además, aprovechando la herramienta Zenhub, se modificó la duración de los
Sprints también en ella para poder extraer los gráficos del trabajo realizado.

Puntos a desarrollar:
\begin{enumerate}
    \item Intervalo de confianza en Democratic Co-Learning.
    \item Control reetiquetado en Democratic Co-Learning.
    \item Correcciones sobre memoria y anexos.
    \item Gráfico de estadísticas unificado.
    \item Internacionalización Web.
    \item Visualización principal de Democratic Co-Learning en la aplicación.
\end{enumerate}

El primer punto fue muy sencillo, se proporcionó la implementación de los
intervalos de confianza tanto de Álvar Arnaiz González como de César Ignacio
García Osorio (tutores) y finalmente se implementó esta segunda.

El control del reetiquetado fue mal estimado (en puntos de historia), al
principio parecía una idea sencilla, pero por un error de pensamiento, la
implementación que se realizó en un principio no funcionaba. Como cada
clasificador tiene su propio conjunto de entrenamiento, se estaba tomando que el
índice de la instancia sumado a la longitud de su conjunto de entrenamiento era
la posición en la que actualizar la etiqueta, obviamente esto no funciona pues
esa suma puede superar la longitud del propio conjunto. Había que almacenar la
posición concreta sin realizar esos cálculos. Se optó por un diccionario de
identificadores para cada clasificador en el que el valor es la posición en las
etiquetas del conjunto del clasificador.

Las correcciones de la documentación se incorporaron según las indicaciones de
Álvar Arnaiz.

El gráfico de estadísticas fue unificado, permitiendo seleccionar al usuario
mediante unos <<checkboxes>>. Aproximadamente unas 4 horas para generar el
formulario correspondiente que controle la aparición de cada línea y controlar
los eventos de las iteraciones (por ejemplo, añadir siguiente punto solo si está
activado su \textit{check}).

En cuanto a la Internacionalización, al principio resultó sencillo, ya que Babel
(Flask-Babel) detecta automáticamente las cadenas de texto dentro de
\texttt{gettext}. Sin embargo, al indicar las traducciones en JavaScript, el
intérprete tomaba \texttt{gettext} como una función que al no estar definida,
lanzaba error. Al final se generó una función en la plantilla principal de tal
forma que actúe como \texttt{gettext}, llamada desde los distintos scripts.

La visualización de Democratic Co-Learning no dio tiempo a implementarse en este
Sprint.

Además, a partir de este Sprint se incorporan todas las tareas en Zenhub para la
generación de los gráficos Burndown (ver
Imagen~\ref{fig:anexos/planproyecto/sprint8}).

\imagen{anexos/planproyecto/sprint8}{Burndown chart del sprint 8.}


\subsection{Sprint 9}
Corresponde con el periodo temporal del 1 al 8 de marzo de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Visualización principal de Democratic Co-Learning en la aplicación.
    \item Formulario de los parámetros de los clasificadores.
    \item Estadísticas generales en Democratic Co-Learning.
    \item Estadísticas específicas en Democratic Co-Learning
    \item Condición de parada re-etiquetado
\end{enumerate}

La visualización principal fue relativamente sencilla pues en realidad es muy
similar a Co-Training. Hubo algún ajuste adicional para generar la información
del \textit{tooltip} al pasar por encima de un punto. Como en cada posición
podía haber varios clasificadores había que mostrar esa información.

Para el formulario de los parámetros se consideró el uso de Flask-WTF que al
final se descartó. Se tenía como punto de partida utilizar un JSON del que leer
los parámetros, así que lo primero fue pensar una forma sencilla de codificarlos
con la información necesaria de las entradas (<<type>>,<<step>>...). 

La ventaja de JSON es que aparte de que la lectura es muy sencilla, son
diccionarios, muy fáciles de utilizar (tanto desde Python como desde las propias
plantillas/JavaScript). Para generar el formulario se pensó en hacerlo de la
forma más automática posible para así solo tener que cambiar el JSON en el
futuro. Esto se hizo con un método de JavaScript que para cada clasificador
genera el formulario correspondiente con los parámetros del JSON. El tiempo
total fue unas 6 horas, pues también se perdió tiempo debido a que no era
posible seleccionar elementos del DOM (pues no estaba cargado) y los elementos
debían seleccionarse mediante CSS (algo que no se sabía por desconocimiento de
JavaScript).

Se añadieron las estadísticas generales de Democratic Co-Learning de forma muy
sencilla pues era exactamente igual que Co-Training (y Self-Training) esto se
realizó añadiendo el \textit{DataFrame} en el propio algoritmo con las
estadísticas deseadas (como el resto de los algoritmos).

Había mucho código muy parecido o exactamente igual en las plantillas de los
algoritmos, así que aprovechando la refactorización, se automatizaron por
completo las estadísticas. Se pensó de tal forma que solo con las columnas de
los \textit{DataFrames} que retornan los algoritmos, la Web ya se encargue de
generar el resto. A la vez que esto (e iniciando la tarea de las estadísticas
individuales), se tuvieron en cuenta las futuras estadísticas individuales para
Democratic Co-Learning. Todas las funciones fueron transformadas para trabajar
con elementos del DOM específicos, de esta forma, al indicarle por ejemplo un
<<DIV>>, se generan las estadísticas sobre ese elemento. En total unas 8 horas. 

Para estas estadísticas individuales, aparte de las funciones generalizadas, se
creó una nueva que sobre un elemento (un <<DIV>>) se generase un selector con el
nombre de los clasificadores que intervienen en el algoritmo junto con los
contenedores (<<DIV>>) dentro de él para las estadísticas de cada clasificador.
Finalmente, se utilizan las funciones de la tarea anterior para añadir a esos
contenedores nuevos los gráficos individuales (uno por cada clasificador). Unas
4 horas.

Sobre el último punto, se comentó que una etiqueta que es re-etiquetada al mismo
valor no debe <<contar>> como mejora (o cambio en el algoritmo). Si no se
realiza así, el tiempo de ejecución aumenta demasiado.


El gráfico Burndown se visualiza en la imagen~\ref{fig:anexos/planproyecto/sprint9}.
\imagen{anexos/planproyecto/sprint9}{Burndown chart del sprint 9.}

\subsection{Sprint 10}
Corresponde con el periodo temporal del 8 de febrero al 15 de marzo de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Comparación sslearn.
    \item Refactorización de plantillas.
    \item Refactorizacion Javascript.
    \item Refactorización Flask (app).
    \item Añadir zoom a los gráficos.
    \item Conceptos teóricos.
\end{enumerate}

En este Sprint no se contaba con demasiado tiempo así que aunque sí se realizó
alguna tarea para añadir funciones, la idea era dedicarlo a mejorar el código y
mantenimiento.

En la reunión del final del Sprint anterior se comentó el cómo se estaban
validando los algoritmos y hasta ese momento solo se habían probado las
utilidades. Se sugirió compararlo contra \textit{sslearn}, una biblioteca de
José Luis Garrido-Labrador~\cite{jose_luis_garrido_labrador_2023_7781117}. Como
primera aproximación, se realizó una validación cruzada completamente manual en
la que se ejecutaba al mismo tiempo las dos implementaciones de los distintos
algoritmos (de momento sin extraer conclusiones). Se tardó unas 3 horas.

El segundo y tercer punto se iniciaron por separado, pero llegó un momento en el
que las funciones que se había creado en JavaScript, si se modificaban un poco,
podrían simplificarse las plantillas. 

Todos los métodos de los gráficos estaban separados por cada uno de los
algoritmos, esto lo hacía muy engorroso porque incluso algún método tenía el
mismo nombre. Se modificaron las funciones de tal forma que fuesen específicas
para cada algoritmo para así juntarlas en un único Script. Por parte de las
plantillas, como había partes repetidas se crearon macros y se identificó una
parte común a todos los algoritmos en su configuración, esto se añadió a la base
de las configuraciones. Todo esto llevó unas 4 horas.

En \texttt{Flask} se tenían varios problemas. El primero era que las
visualizaciones de cada algoritmo tenían un \textit{endpoint} particular, pero
esto no era necesario si se hacía un método para la obtención de los parámetros
de cada algoritmo por separado (y finalmente un solo <<endpoint>> indicándole el
algoritmo en la propia ruta). 

Cuando se crearon esos nuevos métodos se generó código muy parecido porque todos
ellos tenían dos partes: una en la que se obtenían los parámetros que no eran de
los clasificadores base y otra en la que se incorporaban esos parámetros de los
clasificadores. La primera parte es particular para cada algoritmo, pero la
segunda es común a todos. Se creó otro método para ese paso común. 

Por último, por cada algoritmo se tiene un \textit{endpoint} para la ejecución y
obtención de la información de entrenamiento, pero había una parte que todos
hacían prácticamente igual. Se creó un método que engloba: carga de datos,
separación de los datos para entrenamiento, entrenamiento y obtención de los
algoritmos y la aplicación de PCA (o no).

La visualización principal de los algoritmos tenía el problema de que cuando los
puntos estaban demasiado cerca, no se llegan a apreciar individualmente. Esto se
solucionaría aplicando \textit{zoom} al gráfico. Pese a que en cuanto a código
no fuese un desarrollo largo, fue una tarea compleja. Se probaron unas tres
implementaciones parecidas a ejemplos encontrados en la documentación, pero en
todas ellas se perdía la ayuda contextual del \textit{tooltip}. Al final se optó
por volver a empezar de cero con el conocimiento adquirido y junto con un último
ejemplo\footnote{Ejemplo D3:
\url{https://observablehq.com/@d3/zoom-with-tooltip}} y ciertas modificaciones,
se consiguió. 

Posteriormente se añadió el reinicio del \textit{zoom} para volver a la posición
original. El proceso duró unas 5 horas pues cada intento parecía ser definitivo,
pero al final siempre había ciertos límites.

Al final del Sprint se añadieron los conceptos teóricos de Democratic
Co-Learning (conceptos y pseudocódigos).

Aparte de estas tareas se realizaron pequeñas modificaciones: se completó el
estilo adaptable (<<responsive>>), se arreglaron pequeños bugs de
visualizaciones y ayuda contextual, actualización de traducciones y se añadió un
fichero de prueba que el usuario puede descargar si solo quiere probar la
aplicación.

El gráfico Burndown se visualiza en la imagen~\ref{fig:anexos/planproyecto/sprint10}.
\imagen{anexos/planproyecto/sprint10}{Burndown chart del sprint 10.}

\subsection{Sprint 11}
Corresponde con el periodo temporal del 15 al 22 de marzo de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Arreglos en Democratic Co-Learning.
    \item Controlar los límites en los parámetros de los clasificadores.
    \item Modificar las estadísticas generales.
    \item Invertir controles en las estadísticas específicas.
    \item Anexos: Manual del programador.
    \item Modificar validación cruzada.
    \item Comparación exhaustiva contra sslearn.
    \item Añadir validación de los algoritmos a la memoria.
\end{enumerate}

En Democratic Co-Learning se estaba obviando el caso en el que si una instancia
ya estaba etiquetada y esta es reetiquetada, pero además cambiando de etiqueta,
no se consideraba como cambio en el algoritmo. Se ha añadido esta casuística.
Además, Álvar sugirió en el pseudocódigo de la memoria hacer el método de
combinación de hipótesis (predicción) para una sola instancia. Esto se ha
realizado así en la propia implementación (y así el método \texttt{predict} se
encarga de iterar sobre un conjunto de instancias).

Al JSON que codifica los parámetros de los clasificadores base se añadieron los
controles de mínimo y máximo. Esto es porque hay algunos de sus parámetros que
requieren rangos específicos. Ahora la web (JavaScript) genera el formulario de
configuración teniendo en cuenta estos límites.

En la reunión del Sprint anterior se sugirió modificar la visualización de
estadísticas. Para el gráfico general (de estadísticas) no tenía sentido poder
ocultar o no cada una de las estadísticas así que ahora siempre se muestran
todas ellas. Particularmente para Democratic Co-Learning, las estadísticas
individuales estaban manejadas mediante un selector (para seleccionar el
clasificador base) y unos \texttt{checkboxes} para seleccionar las estadísticas
a mostrar. Pero tiene mucho más sentido que el selector sea para las
estadísticas. De esta forma el usuario selecciona una estadística y en el
gráfico puede comparar esa estadística para todos los clasificadores. Además,
los \texttt{checkboxes} se mantienen, pero ahora sirven para elegir qué
clasificadores comparar. Esto llevó unas 6 horas. La organización de las
funciones estaba altamente centrada en la versión anterior, fue un proceso
complicado y lioso.

Pese a que en un principio no se comentó, una vez que se terminó el punto
anterior, se vio necesaria una reestructuración de la página de las
visualizaciones. Se mejoraron las leyendas de tal forma que ya no estaban dentro
de los SVGs, ahora están en su propio cuadro. Esto ha conseguido no preocuparse
por el tamaño de las palabras, centrarla y poder organizar mejor las columnas en
las que se divide esa plantilla.

Sobre el manual del programador, se añadió la estructura de directorios con el
paquete \texttt{dirtree} de \LaTeX{} y se completó el manual del programador,
centrado en qué es lo que debe saber un desarrollador para continuar con el
proyecto. Finalmente se describió el proceso de la compilación, instalación y
ejecución del proyecto. En total fueron unas 6 horas.

El proceso de validación cruzada no estaba bien enfocado, se estaba realizando
de forma manual (y todos los posibles fallos que puede suponer). La librería
scikit-learn incorpora ya utilidades para este proceso. Concretamente se tiene
un método que genera los distintos \textit{Folds} dado un conjunto de datos. El
proceso manual se sustituyó por este nuevo. Se aprovechó para guardar los
resultados como CSV.

Con el proceso de validación cruzada la idea era obtener métricas para
compararlas en alguna gráfica/tabla y comprobar que las implementaciones son
correctas (comparadas con \texttt{sslearn}). Para ello se creó una función que
recogía la información de los CSVs y dibujaba una malla con distintos gráficos.
En las columnas se distribuyen los algoritmos, separadas en dos para la
implementación propia y la de \texttt{sslearn}. En las filas se tiene cada
estadística. Cada uno de los gráficos de esta malla es un gráfico de cajas (para
mostrar mínimos, máximos, medias, medianas...).

Sobre el último punto, aunque la idea era realizarlo en este Sprint, no se
estimó bien la cantidad de trabajo y no pudo ser realizado. Además, en las
ejecuciones del punto anterior (la comparativa) se vio que el algoritmo
Co-Training tenía peor rendimiento que el de \texttt{sslearn}. Esto impedía
justificar en la memoria la validación de los algoritmos.

Durante estas tareas fueron surgiendo pequeños arreglos: Se colorearon las
etiquetas de la ayuda contextual (\texttt{tooltip}) para que quedara claro qué
etiqueta lleva cada punto (no solo el nombre) y se actualizaron las
traducciones.

El gráfico Burndown se visualiza en la imagen~\ref{fig:anexos/planproyecto/sprint11}.
\imagen{anexos/planproyecto/sprint11}{Burndown chart del sprint 11.}


\subsection{Sprint 12}
Corresponde con el periodo temporal del 22 al 29 de marzo de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Completar manual del programador.
    \item Introducción memoria.
    \item Añadir bibliotecas Web.
    \item Añadir explicaciones de los algoritmos en la Web.
    \item Añadir los pseudocódigos en la Web.
    \item Algoritmo Tri-Training.
\end{enumerate}

En el Sprint anterior se empezó el manual del programador, pero quedó pendiente
la compilación, instalación y ejecución del proyecto. Lo primero que se hizo en
este Sprint es finalizar este manual describiendo todos los pasos que un
programador debe seguir para poner en funcionamiento la aplicación.

Para continuar con la memoria, se añadió la sección de la \texttt{Introducción}
como presentación de todo este trabajo.

Las dos principales bibliotecas o recursos utilizados en la Web son
\texttt{Bootstrap} y \texttt{D3.js}, el primer caso es un <<framework>> de CSS
que ya viene con una gran cantidad de clases a utilizar. D3 es la biblioteca de
JavaScript que se ha utilizado para la generación de todos los gráficos. Se
añadió una descripción (y justificación) de uso en la memoria (Técnicas y
herramientas).

Teniendo en cuanta la componente docente de este proyecto, se creyó conveniente
la adición de unas pequeñas explicaciones de los algoritmos. Se añadieron en la
fase de configuración de los algoritmos dado que al mismo tiempo el usuario debe
configurar los parámetros y puede que le permita tener una mayor intuición a la
hora de configurarlo.

En esta misma línea se añadieron los pseudocódigos en forma de imágenes, justo
debajo de las explicaciones. También se creyó conveniente que el usuario pudiera
verlo en la fase de visualización. Se creó un desplegable con la imagen del
pseudocódigo.

Finalmente, y como desarrollo más grande de este Sprint, se creó el algoritmo
Tri-Training. La primera versión (el primer \texttt{commit}) no fue validada de
ninguna forma (se confirmó según se terminó). Esta versión no incluía ninguna
forma de obtener el proceso de entrenamiento, simplemente era el esqueleto
funcional del algoritmo. Obviamente, era claro que iba a haber algún que otro
error. Al principio solo se detectó un error en el que el cálculo del error de
clasificación siempre resultaba en 0. Era una cuestión de pura implementación en
Python así que no fue difícil arreglarlo.

Antes de arreglar este error, la rama en la que se ejecutaba el <<subsample>> no
se estaba realizando en ningún caso. En el momento que se arregló el anterior
error se accedió a esta parte y apareció un nuevo error. Se confundió array de
NumPy con lista nativa de Python y se estaban seleccionando ciertas posiciones
de una lista de Python accediendo a ella con unos índices
(\texttt{List{[}indices{]}}). La solución fue sencilla de igual manera, se
recorría la lista en base la los índices y se creaba esta sublista mediante
compresión de listas.

Al final de este desarrollo, se comparó con una sola ejecución con sslearn. El
nuevo algoritmo tardaba mucho más tiempo que el resto (y que sslearn). Esto era
porque al añadir las predicciones (cuando las otras dos hipótesis coincidían) se
hacía de una en una. Esto se sustituyó para predecir todas las instancias no
etiquetadas y con vectorización. El rendimiento se incrementó mucho.

Durante estas tareas fueron surgiendo otras más pequeñas: Nuevas traducciones,
correcciones de memoria y anexos y una pequeña comparación contra sslearn.

La herramienta Zenhub dejó de proporcionar servicios gratuitos. Esta compañía
actualizó sus planes gratuitos, ya no existe una versión de esas
características. Durante este Sprint <<caducó>> la licencia que se tenía y ya no
se podía acceder a ninguna de sus funcionalidades, tampoco a los gráficos
<<Burndown>>.

\subsection{Sprint 13}
Corresponde con el periodo temporal del 29 marzo al 5 de abril de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Configuración Tri-Training
    \item Visualizar Tri-Training.
    \item Eliminar todo el código duplicado restante de JavaScript.
    \item Documentar JavaScript.
    \item Reestructurar Flask para aplicaciones grandes.
    \item Añadir media geométrica en la validación/comparación contra sslearn.
\end{enumerate}

Para este Sprint el objetivo principal era dejar lista la visualización de
Tri-Training en la Web. 

El primer paso fue incluir las estructuras de datos necesarias en el esqueleto
del algoritmo para ir almacenando la información de entrenamiento. La idea era
igual a Democratic Co-Learning. La realidad es que la forma en la que se
almacenan los datos es muy distinta a todas las demás. Los datos pueden ser
clasificador varias veces por cada clasificador en diferentes iteraciones. Por
lo tanto, para cada clasificador base se almacena una lista para las etiquetas y
para las iteraciones en las que se clasifican. Las estadísticas sí que se
almacenan exactamente de la misma forma que Democratic Co-Learning.

El siguiente paso fue crear la pantalla de configuración de Tri-Training, para
ello simplemente se copiaron las plantillas ya existentes y la misma estructura
que ya se tenía en Flask para las rutas.

Y finalmente, la pantalla de visualización de Tri-Training. Este fue uno de los
pasos más complejos. Como se tenía una nueva estructura de los datos, se tenían
que crear los métodos que permitiesen interpretarlos, de forma general, los que
se ha realizado es comprobar, en cada iteración, qué clasificador han añadido
datos etiquetados nuevos junto con su etiqueta. Para que el usuario pudiera ver
los cambios que ocurren en cada iteración, cuando pulsa en la siguiente
iteración se descoloran los puntos (a gris) y después se colorean los nuevos,
todo esto mediante animaciones y con un cierto tiempo para que pueda darse
cuenta.

En cuanto a JavaScript, se documentaron por completo todos los métodos que
fueron creados para este proyecto. Además, se eliminó el código duplicado en
cada fichero utilizando métodos comunes. También fue un proceso largo, sobre
todo para comprobar que las modificaciones eran correctas y generales, en
principio, todo parece correcto.

Se reestructuró completamente Flask, esto es porque tal y como se encontraba la
aplicación, era muy básica y general. Los proyectos más grandes con Flask tienen
una estructura más o menos concreta. Esta es la idea que se ha intentado
aplicar, utilizando <<Application Factory>> y <<Blueprints>>. Pero sobre todo,
para hacerla más mantenible y extensible. De hecho, aunque no está siendo usada,
se tiene una pequeña base de datos para posibles adiciones futuras. 

Esta reestructuración causó muchos problemas en cuanto a las rutas de ficheros.
Se tuvieron que especificar manualmente y usar la librería del sistema operativo
de Python para independizar ciertos tratamientos de ficheros del sistema
operativo concreto donde se ejecute la aplicación (se ha probado en Windows y
Linux).

Finalmente, se añadió la media geométrica como métrica de validación a la hora
de comparar contra
\texttt{sslearn}~\cite{jose_luis_garrido_labrador_2023_7781117}. Además, en
Sprints anteriores se comentó la idea de utilizar \textit{Violinplots}, que
resultan más pertinentes para los casos de comparación.

\subsection{Sprint 14}
Corresponde con el periodo temporal del 5 al 12 de abril de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Actualizar manual del programador
    \item Rediseño Web completo
    \item Ayuda contextual y errores en Web.
    \item Anexos: Diseño
\end{enumerate}

Debido a las modificaciones realizadas en los recientes Sprints, el manual del
programador quedó desactualizado. El cambio más notable fue la nueva
reestructuración de Flask. Se actualizó el árbol de directorios reflejando esta
nueva estructura. También se actualizaron todas las explicaciones posteriores
del manual.

El diseño de la Web estaba hecho prácticamente desde el principio de la Web y
resultaba muy poco llamativo. El primer paso para este rediseño fue elegir una
paleta de colores, se creyeron convenientes fondos oscuros con alguno más claro
para dar contraste.

Para continuar, se pensó en la disposición y estilo general del contenido. Hasta
el momento la página resultaba muy plana, sin cambios entre las distintas partes
de la página. Consultando páginas Web de ejemplo parecía interesante y bonito
crear efectos de sombra y se estableció como estilo general de la página. A
partir de aquí las distintas secciones de una misma página se encuadran en un
elemento con sombra, para llamar la atención del usuario. Además, para comprobar
que no eran ideas descabelladas, se consultó a compañeros y personas externas
para buscar opinión. Gracias a esto se realizaron retoques (cambio de algún
color, títulos, disposiciones...) que no convencía a la mayoría.


Para proporcionar ayuda básica en las distintas páginas, se creó una macro que
genera una \texttt{tooltip} con un mensaje. Tanto en la subida como en la
configuración se utilizaron estos mensajes para aclarar aspectos confusos. Como
adición, resultaba muy molesto tener que volver a subir un fichero
constantemente al seleccionar otro algoritmo durante la misma sesión. Se añadió
una comprobación en la pestaña de subida en la que si ya se había subido un
fichero, permitiera ir directamente a la configuración.

Durante todo el desarrollo hasta este momento, ocurrían ciertos errores HTTP
(404, por ejemplo) pero no eran controlados. Se creó una plantilla base y se le
indicó a Flask los errores que debía manejar y renderizar en esa plantilla. Se
han añadido los más comunes (y además muchos de ellos no han llegado a ocurrir
nunca).

En reuniones anteriores se comentó que debía explicarse las estructuras de los
ficheros JSON que maneja e interpreta la Web (JavaScript). Se añadieron todas
las explicaciones relativas a la generación de estos ficheros desde la propia
ejecución de cada algoritmo. Se creó también un diagrama de secuencia con la
interacción general con la Web para la visualización de un algoritmo.

\subsection{Sprint 15}
Corresponde con el periodo temporal del 12 al 19 de abril de 2023.

Durante este Sprint tuvo lugar el periodo de exámenes parciales de las
asignaturas cuatrimestrales, y junto con las prácticas en empresa, no se pudo
mantener la prioridad al desarrollo del proyecto. Por lo tanto, no existen
puntos concretos a desarrollar, pero la idea era realizar, en la medida de lo
posible, retoques en el mismo.

Los \texttt{violinplots} que se añadieron para la comparativa de algoritmos
resultaban algo confusos. Aunque este tipo de gráficos se utiliza mucho para
comparar datos, para este ámbito concreto no resultó ser la mejor opción. La
parte superior de estos gráficos, que no son el máximo de los datos, sobrepasa
en algunos casos el valor máximo de las estadísticas. Esto hace parecer que los
cálculos son incorrectos. Se volvió a incluir los gráficos de caja anteriores.

Como no resultaba una tarea grande, se incluyó la integración continua a partir
de este momento. La herramienta SonarCloud proporciona muchas métricas de
calidad del código (bugs, línea duplicadas, seguridad...). Gracias a estos
análisis se realizaron todas las posibles modificaciones para reducir las
alertas que hasta el momento podían abordarse. Por ejemplo, la protección contra
CSRF (\texttt{Cross-Site Request Forgery}) no se había contemplado, pero la
herramienta sí lo considera como un elemento prioritario.

\subsection{Sprint 16}
Corresponde con el periodo temporal del 19 al 26 de abril de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Añadir usuarios (con login y registro)
    \item Crear un espacio personal para los usuarios
    \item Continuar con la memoria
    \item Estandarización en la configuración
\end{enumerate}

Durante este Sprint se iniciaron las tareas para mantener usuarios en la
aplicación. El primer paso para realizar esto fue la creación del modelo de
usuario en la base de datos. El usuario es simple, con un identificador, nombre,
email y contraseña (este no es el objetivo principal de la aplicación).

A continuación, se crearon los pares de \texttt{endpoint} y plantilla para
inicio de sesión y registro. Como este tipo de formulario requiere de una
validación exhaustiva y que permita dar al usuario ayuda contextual, se utilizó
Flask-WTForms para ello porque tanto desde el navegador como desde el
\texttt{backend} permite esta validación. Esto trata los formularios como
objetos, que incluso cada uno de ellos mantiene una lista de errores. En ambos
\texttt{endpoints}, se realizan las típicas comprobaciones: al registrar que no
exista ya una cuenta con el mismo email, en el inicio de sesión que la
contraseña coincida con la almacenada, que exista el email... Respecto a las
contraseñas, solo se almacena el Hash (SHA256) por lo que no se podría obtener
la cadena real de vuelta (de forma sencilla). Y como se comentaba, cuando se
detecta un error de este estilo, se muestra un mensaje (en rojo) con lo que ha
ocurrido.

Con todo ello, se modificó la barra de navegación incluyendo el menú de los
usuarios: Registrarse/Iniciar sesión y una vez el usuario ha iniciado sesión, un
menú desplegable que le llevaría a su espacio personal y perfil.

Antes de continuar con el desarrollo, se incluyó un \textit{mockup} con lo que
se tenía pensado hacer.

Para que el usuario pudiera modificar sus datos, se creó otro pequeño formulario
muy parecido al de registro. Por su puesto, con su correspondiente ruta
(\texttt{/perfil}) que valida que los datos introducidos son correctos.

Del mismo modo, era interesante que el usuario pudiera ver algo de su
actividad, la idea era guardar los conjuntos de datos que ha subido para poder
volver a utilizarlos y un historial de ejecuciones con el objetivo de replicar
exactamente esa ejecución. Como se vio que la ruta del perfil y esta nueva eran
parecidas, se unificó el estilo de tal forma que en la columna de la izquierda
apareciesen los principales datos del usuario y a la derecha, o bien la
modificación del perfil (\texttt{/perfil}) o su actividad (\texttt{/miespacio}).

Antes de seguir, para poder almacenar toda esta actividad, se crearon dos nuevas
entidades <<Dataset>> y <<Run>> que almacenarían la información principal como
los nombres de los ficheros, fecha de subida/ejecución...

La parte visual de la actividad se realizó con DataTables, un plug-in de jQuery
que proporciona mucha versatilidad para hacer tablas. Los datos no provenían de
las plantillas, se crearon nuevas rutas a las que hacer peticiones (como una
API). Una vez que se había trasteado con este plug-in e incluso vista la forma
en la que eliminar filas, la idea es realizar una petición y que los datos
recibidos sean incrustados en estas tablas. La obtención de los datos no fue un
problema, se utilizaron los <<fetch>> de JavaScript y cuando se obtenía
respuesta, se creaban las tablas. El verdadero problema fue la incorporación de
acciones (como la de borrar), en la propia documentación de DataTables y gracias
a su foro, se consiguieron generar botones en esta columna (con puro HTML). El
siguiente reto fue crear otras peticiones como respuesta a los clics de estos
botones. La suerte fue que DataTables permite obtener los datos de una fila
directamente, lo que resultó de mucha ayuda para, por ejemplo, extraer el nombre
de un fichero y posteriormente incorporarlo a las peticiones de borrado. Se
añadieron también unos \textit{modales} para las comprobaciones del usuario.

El desarrollo anterior se ha simplificado, primero se creaban versiones
sencillas y luego se iban incorporando retoques hasta el resultado final. Por
ejemplo, al final del todo, se añadió el estilo <<\textit{responsive}>> a estas
tablas. La ventaja fue que DataTables ya tenía extensiones que realizaban esto
automáticamente.

Continuando con la memoria, se añadieron los objetivos de proyecto y el comienzo
de aspectos relevantes.

A la vez que se iban incorporando estas adiciones, no se perdía de vista el
resto de la aplicación, en la fase de configuración de los algoritmos resultaba
conveniente permitir al usuario estandarizar o no el conjunto de datos a mostrar
(hasta ahora siempre se estandarizaba), se incluyó un interruptor para ello.

Además de todo esto, se hicieron algunos cambios pequeños: <<Footer>> al final
de la página, selección de fuentes para la página, arreglar algunos bugs menores
o estilar el <<card>> del perfil.

\subsection{Sprint 17}
Corresponde con el periodo temporal del 26 de abril al 3 de mayo de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Botón de idioma.
    \item Panel de administración.
    \item Bootstrap icons.
    \item Mensajes flash (alertas).
    \item Actualizar técnicas y herramientas.
\end{enumerate}

Lo primero que se hizo fue sustituir los SVG de los iconos que se estaban
utilizando, por clases de \texttt{Bootstrap Icons}. Era muy engorroso tener cadenas tan
grandes de texto y esta modificación solo conlleva añadir un enlace.

Lo siguiente que se realizó fue añadir un botón para cambiar el idioma. La idea
es muy sencilla, las traducciones ahora se realizan detectando qué idioma se
ajusta más al navegador del usuario (en las peticiones existe un <<header>> que
incluye esta información), como también se quiere que el usuario decida, todas
las peticiones son procesadas previamente por un \texttt{endpoint} (Flask
permite esto) que detecta si existe un parámetro <<lang>> (\texttt{?lang=X}) y
si lo hay, establece el idioma a este (guardándolo en la sesión). De esta forma
se consigue no modificar lo ya existente.

El panel de administración fue un verdadero reto, como no se quería tener que
hacer todo de cero (mucho código duplicado), se tuvo que pensar primero la forma
de aprovechar las tablas que ya se habían creado. El panel de administración
solo iba a tener una tabla nueva, además de la de los ficheros y ejecuciones que
ya existían. Estas últimas son las que se debían reutilizar. Para ello, la
información que debía ver el administrador además de lo que ya se mostraba era
el usuario al que pertenecen los ficheros y ejecuciones. Se añadió esta columna
a las tablas y las funciones se parametrizaron con un <<flag>> que permitiese
especificar si la tabla debe generarse como administrador o como usuario normal.
En el caso del panel de administración, mostrar esa columna de usuarios. Esto
conllevó a modificar también los modelos pues hasta ahora solo se almacenaba una
clave foránea con el identificador del usuario (había que añadir el email) con
una relación uno a varios.

Finalmente, se creó la tabla de usuarios del mismo modo que el resto, creando
una ruta donde consultar todos los datos y añadir las acciones correspondientes
de editar el usuario o eliminarlo. Se reutilizó mucho de lo que ya se había
codificado. La ventaja es que, aunque se tuvieron que añadir bastantes cosas, ya
se tenía el conocimiento previo fue más laborioso (el desarrollo anterior se
dividió en varios días) pero menos difícil.

Además de lo comentado anteriormente, se quiso incluir unas estadísticas
sencillas en cada una de las tablas. Para los usuarios, el total y para los
ficheros subidos y ejecuciones, el total de los últimos siete días.

Finalmente se tuvo que modificar algún \texttt{endpoint} para aumentar las
comprobaciones de seguridad y sobre todo, para evitar duplicar código. Por
ejemplo, la edición de un usuario por parte de un administrador se <<delega>> al
propio \texttt{endpoint} del perfil. En esta línea, a medida que pasaba el
Sprint, mejoraban las comprobaciones y controles de errores y para que el
usuario tuviera algo de información, se añadió un modal que se activa cuando
ocurre un error.

Los mensajes flash se modificaron como alertas de Bootstrap de tal forma que el
color de las mismas dependiera de las categorías (se añadieron estas a todos los
puntos en los que se lanzaba un mensaje flash).

Se actualizó el apartado de las técnicas y herramientas hasta este punto.

Además, también se realizaron otras modificaciones:

\begin{itemize}
    \item Añadir eliminación de ejecuciones: Al igual que usuarios y ficheros,
    era interesante que pudieran eliminarse las ejecuciones.
    \item Bug de edición perfil: Si la contraseña actual se introducía correcta,
ocurría un error crítico (no se habían pasado todas las variables a la plantilla
porque el código no estaba actualizado).
    \item Bug reducción dimensionalidad: Cuando se desactivaba PCA y se incluía
la misma columna en CX y CY, ocurría una excepción. Pandas parece no permitir
concatenar una columna a un DataFrame que tiene columnas idénticas.
    \item Refactorizaciones generales para evitar código duplicado.
\end{itemize}

\subsection{Sprint 18}
Corresponde con el periodo temporal del 3 al 10 de mayo de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item <<Toasts>> como alertas.
    \item Arreglar visualizaciones (\texttt{tooltips}).
    \item Cambiar formularios a WTForms.
    \item Mostrar parámetros de las ejecuciones en el historial.
    \item Conceptos teóricos Tri-Training.
    \item Conceptos teóricos HTTP.
\end{enumerate}

En primer lugar, el aspecto que se le había dado a los mensajes <<Flash>> de la
aplicación parecía un poco pobre. Bootstrap tiene los llamados <<Toasts>> que
son avisos más sofisticados y estilados. Partiendo un ejemplo de la
documentación, simplemente se filtra por la categoría del mensaje (error,
advertencia, información...) y se genera el <<Toast>> con unos colores acordes.

Durante el Sprint anterior se estuvieron probando las visualizaciones. El
problema es que los \texttt{tooltips} muestran información confusa.

En primer lugar, estos recuadros que aparecen al pasar el ratón por un punto, no
se posicionaban correctamente. Mediante un ejemplo encontrado en
Internet\footnote{Ejemplo de \texttt{tooltip}:
\url{https://observablehq.com/@clhenrick/tooltip-d3-convention}}, se vio que el
propio D3 tiene una función que determina la posición del ratón correctamente.
Además, el elemento \texttt{tooltip} tenía una posición absoluta respecto de
toda la página para arreglarlo, se le añadió la posición relativa al contenedor.
Esto se aplicó a los cuatro algoritmos.

El mayor problema era arreglar la información confusa. Como es obvio, el
conjunto de datos que introduzca el usuario puede tener puntos duplicados y
además al realizar PCA, puede ocurrir que dos datos aparezcan en la misma
posición. Esto no se estaba contemplando y no se indicaba. Es aún más confuso en
Democratic Co-Learning y Tri-Training pues cada punto puede ser clasificado por
varios clasificadores e incluso en varias iteraciones.

Para ayudar al usuario a tener toda la información, el \texttt{tooltip} muestra
ahora los puntos duplicados. Es decir, cuando solo hay un punto, simplemente
mostrará la información normal, pero cuando haya puntos solapados (quizá por
PCA o porque en el propio conjunto hay datos duplicados), los detectará y
mostrará un identificador de duplicado en orden creciente.

Para determinar esto lo que se ha hecho es comprobar (mediante diccionarios) si
un punto ya había sido visto, en cuyo caso existen puntos solapados.
 
Otra cosa añadida al \texttt{tooltip} es la iteración de clasificación. Cuando
el punto se acaba de clasificar o estamos en una iteración posterior, al lado de
la etiqueta se muestra entre paréntesis la iteración en la que se clasificó.

Al final del Sprint (y justo coincidiendo con una reunión de seguimiento), se
planteó que el \texttt{tooltip} podía ser simplificado. Por una parte, cada vez
que se muestra todos los puntos, cada uno de ellos tiene su posición X e Y.
Ahora solo se muestra como si fuera un título una única vez.

Otra idea era que no se mostrase información futura (para Democratic Co-Learning
y Tri-Training). Por ejemplo, si dos clasificadores habían etiquetado un punto
en iteraciones 4 y 5 respectivamente, hasta ahora, en la iteración 2 (por
ejemplo), el \texttt{tooltip} tenía <<reservado>> el espacio para escribir esos
dos etiquetados. El comportamiento bueno sería que en una iteración menor que 4
simplemente mostrase un único texto para ese punto (ejemplificando que todavía
no ha sido etiquetado). Cuando se llega a la iteración 4, se mostrará la
etiqueta que le dio el primer clasificador, pero sin mostrar todavía el de la
iteración 5. Y así sucesivamente.

En cuanto a los formularios, los de configuración del algoritmo estaban hechos
directamente en HTML. Dado que se había empezado a utilizar WTForms (inicio de
sesión, registro...), era conveniente modificarlos y trabajar con esta librería.
Todos los formularios tienen una parte común, lo primero que se hizo es crear
una clase de formulario base del que el resto extendería. A partir de aquí,
simplemente se trasladó todo lo que se tenía en HTML a los distintos
\texttt{Fields} de WTForms. En el HTML simplemente se hace referencia a estos
campos. Fue un proceso laborioso aunque sencillo.

Esto además permitía añadir el <<token>> CSRF para arreglar ciertas
vulnerabilidades.

En la tabla del historial de ejecuciones faltaba la posibilidad de ver los
parámetros de las ejecuciones. Para verlos, se añadió un campo de texto en la
entidad de la base de datos de ejecuciones. 

El formato JSON se pensó que era suficientemente legible como para mostrar los
parámetros con él. Para ello, se creó una función (en Python) que transforma
todos los parámetros que provienen del formulario de configuración en un
diccionario. Este diccionario luego es transformado en texto para almacenarlo en
ese campo nuevo.

Desde la Web, simplemente se lee ese campo de la ejecución y se formatea como
JSON. Existe un nuevo botón en la tabla que permite mostrar un <<modal>> con los
parámetros.

Se añadieron los conceptos teóricos de HTTP, con una descripción del protocolo,
la estructura de las peticiones, \texttt{cookies} y el ataque CSRF (Cross-Site
Request Forgery) junto a su solución (<<CSRF token>> comentado anteriomente).

En cuanto a Tri-Training, se añadió el pseudocódigo del mismo.

Además, también se realizaron otras modificaciones, las más notorias:
\begin{itemize}
    \item Añadir favicon.
    \item Control de errores.
    \item Arreglar bugs en las tablas del espacio personal.
    \item Añadir algún aspecto relevante.
\end{itemize}


\subsection{Sprint 19}
Corresponde con el periodo temporal del 10 al 17 de mayo de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Anexo requisitos.
    \item Anexo documentación de usuario.
    \item Actualizar manual del programador.
    \item Diseño arquitectónico.
    \item Técnicas y herramientas
    \item Conceptos teóricos del tratamiento de datos.
\end{enumerate}

En este Sprint se quería aumentar bastante la documentación. El primer objetivo
era realizar el anexo de los requisitos. Lo primero fue añadir el catálogo de
requisitos que la aplicación debía realizar.

A continuación, se realizó un primer diagrama de casos de uso general. A partir
de este, se realizó la descripción de todos ellos (con sus pasos,
precondiciones, excepciones, requisitos asociados...). Sin embargo, durante la
realización de estos, se vio que el diagrama podía ser simplificado. El
administrador, al igual que los usuarios, pueden eliminar los ficheros y
ejecuciones, y por esta razón realizan el mismo caso de uso en ambos casos. 

Se actualizó el diagrama de casos de uso y se añadieron todas las descripciones
acordes de todos ellos.

El anexo de la documentación de usuario se podría realizar más adelante por si
la aplicación sufre algún cambio final. Sin embargo, estos cambios serán,
probablemente, en cuanto aspecto. Es por esto que las instrucciones útiles para
el usuario serán las mismas. Además, resultaba una tarea apetecible en esos
momentos. En este manual se explicó todo lo que un usuario podía realizar
(anónimo o registrado). Además, como también existe un rol administrador, se
describieron todos sus privilegios.

En el anexo del diseño se añadió el diseño arquitectónico que se ha planteado
para la aplicación, una arquitectura de tres capas. Se explicaron los conceptos
relativos junto a cómo se reflejaba en la aplicación global.

Se añadió PEP8 a las técnicas y \texttt{Draw.io}, \texttt{Putty} y
\texttt{Bootstrap Icons} en las herramientas.

Y por último, como otro gran apartado de este Sprint, se añadieron algunos
conceptos que se han utilizado en la aplicación sobre el tratamiento de datos.
Pese a que la aplicación no realiza un pre-procesado completo, convenía explicar
la codificación de variables categóricas, el análisis de componentes principales
(PCA) y la estandarización que se puede aplicar a los datos al visualizarlos.

Además, también se realizaron numerosos cambios:
\begin{itemize}
    \item Se eliminó el efecto <<hover>> en la barra de navegación que causaba
    muchos problemas en móviles.
    \item Los parámetros mostrados en las ejecuciones se muestran de forma
    legible (nombre apropiados, no los identificadores de los formularios) y con
    traducciones acordes.
    \item Control de errores en la visualización.
    \item Pseudocódigo Tri-Training (actualizado y añadido a Web).
    \item Fijar dependencias del proyecto.
    \item Se mejoró la comprobación de las extensiones de ficheros para que
    obligatoriamente terminen en <<.arff>> o <<.csv>>.
    \item Diagrama de despliegue en el diseño.
\end{itemize}

\subsection{Sprint 19}
Corresponde con el periodo temporal del 17 al 24 de mayo de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Análisis de viabilidad: económica y legal.
    \item Añadir Scrum como técnica.
\end{enumerate}

El desarrollo se vio ralentizado en este Sprint debido al periodo de
convocatoria final.

Para ir completando los anexos se añadió tanto la viabilidad legal como
económica. En el caso de la económica se contaba con algún ejemplo de cómo se
debía realizar de alumnos previos (proporcionado por los tutores). Durante su
desarrollo se contemplaron todos los costes derivados (suposiciones) de los
empleados y de activos \textit{hardware} y \textit{software}. Además, se tomó la
decisión lógica de no incluir beneficios, ya que se trata de una aplicación
completamente docente y pensada para que cualquiera pueda usarla.

En cuanto a la legal, se estudiaron todas las licencias del \textit{software}
que se ha empleado para determinar cuál sería la correcta. Finalmente se escogió
la licencia BSD 3-Clause.

Como la metodología Scrum es altamente utilizada (y ya no resulta una clara
novedad), se incluyó en las técnicas una pequeña explicación de todo lo que
interviene en ella.

\subsection{Sprint 20}
Corresponde con el periodo temporal del 24 al 31 de mayo de 2023.

Puntos a desarrollar:
\begin{enumerate}
    \item Añadir la validación de los algoritmos.
    \item Terminar conceptos teóricos.
    \item Añadir la descripción de los formatos de \textit{tooltip}.
    \item Añadir pruebas del sistema.
    \item Revisión general.
\end{enumerate}

En sprint lo que planificó era tener todo el proyecto lo más cerca posible al
objetivo para que una vez se realice la reunión del sprint evaluar cuál es el
estado.

En primer lugar, algo que se estaba retrasando constantemente debido a la
prioridad de nueva funcionalidad era la validación de los algoritmos. En este
sentido sí que se tenían bastante probados, pero faltaba añadirlo a la
documentación.

Como se venía comentado en sprints anteriores, esta validación se trata de
comparar la implementación propia contra la de \emph{sslearn} mediante gráficos
de cajas. La idea es que si se obtienen resultados similares en las estadísticas
comparadas, se puede concluir que la implementación propia es \emph{correcta}.
El resultado final con la ejecución de cada algoritmo con varios conjuntos de
datos fue positivo y se concluyó que eran correctos.

Un punto a destacar de la validación fue la diferencia de implementación de
Co-Training. En líneas generales, lo que se pudo observar de \emph{sslearn} es
que el tamaño de \textit{pool} era más grande que lo que se venía realizando.
Esto se subsanó aumentando los parámetros en la llamada al algoritmo propio para
hacerlo lo más parejo posible. Aunque sigue apareciendo mayor variación que el
resto de los algoritmos, se puede comparar perfectamente y llegar a la misma
conclusión.

En cuanto a los conceptos teóricos, se añadió la descripción de Tri-Training (el
pseudocódigo ya estaba incluido). Para ello se revisó de nuevo el artículo
correspondiente para incluir la idea general más importante.

Algo que podía ser muy confuso para un usuario nuevo es la multitud de formatos
de \textit{tooltip} de la visualización. Se añadió la explicación de cada uno
para cada algoritmo en el manual de usuario.

En cuanto a los anexos (a expensas de revisar y perfeccionar), el apartado que
faltaba era el de las pruebas del sistema en el manual del programador. Por
sugerencia de los tutores, se ha utilizado Selenium como entorno de pruebas.
Además, en la asignatura de Validación y Pruebas se utilizó Katalon Recorder,
que utiliza Selenium. Esto facilitó la parte de las pruebas automáticas.

La idea de las pruebas era tener los suficientes casos de prueba que asegurasen
el funcionamiento de la aplicación. De hecho, durante algunos cambios que se
hacían, se volvían a ejecutar para comprobar que esos cambios no rompían la
aplicación. En total fueron 17 casos de prueba teniendo en cuenta las
visualizaciones, los usuarios (y sus permisos) y las acciones de estos
(incluidas las del administrador).

Durante todo el sprint se intentaba corregir todo lo que se veía como mejora
(revisión general). Entre estas correcciones están:
\begin{itemize}
    \item Arreglar el posicionamiento de los \textit{tooltips} de ayuda
    contextual (no los de la visualización) sustituyéndolos por los de bootstrap.
    \item Arreglar adaptabilidad en el panel de administración ya que las tablas
    de las pestañas dos y tres no se ajustaban (solo la primera).
    \item Las rutas de los usuarios fueron anonimizadas, en el sentido de que
    hasta ahora se incluía por ejemplo el identificador del usuario en la base
    de datos (algo como \texttt{/perfil/2}). Convenía no mostrar estos valores
    (\texttt{/perfil}).
    \item Traducciones.
    \item Justificar el por qué de la licencia BSD 3-Clause.
\end{itemize}

\subsection{Sprint 21}
Corresponde con el último periodo temporal (considerando hasta la entrega).

Puntos a desarrollar:
\begin{enumerate}
    \item Enlazar el manual en web.
    \item Logos de los algoritmos.
    \item Depurar aplicación.
    \item Completar memoria (resumen, conclusiones y líneas futuras).
    \item Añadir videotutoriales.
    \item Completar anexos.
\end{enumerate}

En principio, como sprint final, no se planteaba realizar ninguna
implementación. Quizá alguna modificación/mejora que no altere el
funcionamiento.

En primer lugar, se añadió en la barra de navegación un enlace directo al manual
de usuario de la propia documentación del proyecto. Esto conllevó la
actualización de las capturas del manual para que se apreciara el nuevo icono y
un nuevo caso de uso sencillo.

En la aplicación web faltaban los logos de los algoritmos. Para ello, se generó
un modelo de un robot en Dall-e\footnote{\url{https://openai.com/dall-e-2}}
(consejo de los tutores). A partir de aquí, se fue modificando el logo base
adecuándolo al contexto de los algoritmos.
\begin{itemize}
    \item SelfTraining: Único robot.
    \item Co-Training: Son dos clasificadores (dos robots) pero están combinados
    (funcionamiento interno del algoritmo), ya que es como si actuaran como uno
    solo, pero cada uno ve una parte de los datos (\emph{multi-view}).
    \item Democratic Co-Learning: Tres robots con su papeleta de voto (se basa en la votación).
    \item Tri-Training: Se combina el conocimiento (predicciones) de dos
    clasificadores para que un tercero aprenda.
\end{itemize}

En cuanto a la depuración de la aplicación lo que se intentó fue mejorar la
interacción del usuario. En este sentido, se modificaron los formularios de
configuración de Self-Training y Co-Training.

En Self-Training el límite o \textit{threshold} ya no se realiza con un
\textit{placeholder}, sino con un rango de porcentaje, más sencillo de usar.
Además, se ha incluido un \textit{tooltip} indicando que si introduce 0 en el
número de iteraciones no se limita internamente (0 es como infinito).

En Co-Training se ha añadido el \textit{tooltip} del número de iteraciones como
Self-Training (al poner 0 es como si fuera infinito). También se ha añadido
control del formulario para impedir que el número de positivos y negativos sean
nulos a la vez.

Tanto en Democratic Co-Learning y Tri-Training se ha incluido la comprobación de
diversidad en los clasificadores (deben ser diversos, diferentes). Se muestra un
mensaje en el caso de que no sean distintos. De hecho, al entrar en la
configuración, aparecen seleccionados tres distintos.

Entre otras mejoras, en el gráfico de estadísticas, cuando había muchas
iteraciones, los números se solapaban. Se realiza una operación de división
entre 35 (a partir de este los números se solapaban) y ese resultado actúa de
divisor en el número de <<rayitas>> dibujadas en las iteraciones. De esta forma,
se evitan los solapamientos, pero se mantienen suficientes marcas.

Durante unos días se sustituyó los enlaces <<CDN>> (para descargar los recursos
o bibliotecas) por ficheros locales descargados. Esto fue revertido pues
convenía delegar estas descargas al usuario (no sobrecargar el servidor con
tráfico innecesario).

Como último punto a destacar (además de otros retoques menores), se incorporó la
expiración de las \textit{cookies} de sesión. Cuando el usuario cierra el
navegador, esta \textit{cookie} es eliminada (al volver a la aplicación será
como la primera vez).

Al mismo tiempo que se fue depurando la aplicación se iba finalizando con la
memoria. Se añadieron las conclusiones derivadas, el resumen del proyecto y las
líneas futuras para la expansión de la aplicación. 

Además, tanto para la memoria como los anexos se fueron corrigiendo los errores
vistos por ambos tutores.

Para los anexos, también se fueron incorporando los elementos que faltaban (como
el diagrama de componentes) y completando aquellas partes con alguna explicación
más o aclaración. Por último, se añadieron unos videotutoriales (enlazados a
esta documentación) para ejemplificar las principales acciones de los usuarios
(anónimos, registrados y administradores).

Y en definitiva, aquí concluye el desarrollo proyecto. Ha sido un largo camino e
intenso, pero gratificante y con mucho aprendizaje.

\clearpage
\section{Estudio de viabilidad}

\subsection{Viabilidad económica}

El estudio de la viabilidad económica viene a evaluar cuáles son los costes
derivados del desarrollo del proyecto y beneficios esperados.

Aún con todo esto, el contexto del proyecto, desde el inicio, se ha marcado como
una aplicación de tipo docente. Esto tendrá ciertas implicaciones que se irán
comentando durante este estudio.

Se supondrá un entorno real de una empresa creada con el fin de llevar a cabo
este proyecto. Esta empresa contará con un empleado desarrollador (alumno), dos
supervisores (tutores) y los activos hardware y software. El comienzo oficial
del proyecto fue el 25 de enero de 2023 y su fecha límite estipulada es el 8 de
junio (unos 5 meses). 

\subsubsection{Costes}

\textbf{Empleados}:

El desarrollador ha realizado una media de 4.5 horas diarias (progresivamente
aumentando hasta la fecha límite de entrega): unas 3 horas en días laborables y
en los fines de semana se empleaban alrededor de las 8 horas.

El cómputo del salario bruto del alumno, suponiendo un salario de
11\texteuro/hora, según lo estipulado en las bases mínimas de Ingenieros y
Licenciados en~\cite{cotizacion2023} es:

\begin{center}
$4.5 \frac{horas}{día} \times 7 \frac{días}{semana} \times 11
\frac{\text{\texteuro}}{hora} \times 4 \frac{semanas}{mes} = 1\,386\frac{\text{\texteuro}}{mes} $
\end{center}

Para el caso de los supervisores (tutores), el tiempo empleado de ambos es de 2
horas/semana para la revisión del progreso y reuniones. Por lo que, suponiendo
mismas bases mínimas anteriores, y añadiendo cuatro euros debido al cargo
superior, el salario bruto es:

\begin{center}
$2 \frac{horas}{semana} \times 15 \frac{\text{\texteuro}}{hora} \times 4
\frac{semanas}{mes} = 120\frac{\text{\texteuro}}{mes} $
\end{center}


Constituido el salario bruto que recibe cada empleado, deben añadirse todos los
impuestos de la Seguridad Social estipulados para el año 2023. Estos impuestos
están recogidos en la web oficial de la seguridad social en el <<Régimen General
de la Seguridad Social>> en~\cite{cotizacion2023}.

En la tabla~\ref{tabla:seg-social} se puede ver un resumen de los impuestos que
han de aplicarse al salario bruto de los empleados considerando categorías
generales.

\begin{table}[H]
    \centering
    \begin{tabular}{lr}
        \toprule
    \textbf{Concepto}           & \textbf{Impuesto(\%)} \\ \midrule
    CONTINGENCIAS   (Comunes)   & 23,60 \\
    DESEMPLEO  (Tipo General)   & 5,50 \\
    FOGASA                      & 0,20  \\
    FORMACIÓN PROFESIONAL       & 0,60 \\ \bottomrule
    \end{tabular}%
    \caption{Tabla de impuestos}
    \label{tabla:seg-social}
\end{table}

Por lo que la fórmula del cómputo total que la empresa debe pagar por los
empleados es:

\begin{figure}[H]
\begin{center}
    $Gasto~de~la~empresa = \frac{Salario}{1-(0.236+0.055+0.002+0.006)}$
\end{center}
\caption{Cálculo del gasto de la empresa por empleado}
\end{figure}


\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrr}
\toprule
\textbf{Empleado}                               & \textbf{Salario bruto (€)}       & \textbf{Gasto de la empresa (€)}      \\ \midrule
David Martínez Acha (des)               & 1\,386                    & 1\,977,18                      \\
Álvar Arnaiz González (sup)             & 120                      & 171,18                       \\
César Ignacio García Osorio (sup)       & 120                      & 171,18                       \\ \midrule
\textbf{Total}                          & 1\,626                    & 2\,319,54                      \\ \midrule
\textbf{Total 5 meses}                  & 8\,130                    & 11\,597,7                      \\ \bottomrule
\multicolumn{3}{l}{\begin{tabular}[c]{@{}l@{}}des: desarrollador\\ sup: supervisor\end{tabular}}
\end{tabular}%
}
\caption{Salarios brutos y coste que supone a la empresa}
\label{tabla:salarios}
\end{table}

En la tabla~\ref{tabla:salarios} se presentan todos los costes de los empleados.
El total, para los 5 meses de duración aproximada es 11\,597,70\texteuro.

\textbf{Hardware}:

Para desarrollar el proyecto se ha utilizado un ordenador de sobremesa montado
por piezas. Está compuesto por un AMD Ryzen 7 5800X de 8 núcleos a 3.8 GHz, 16
GB de memoria RAM y 1TB SSD NVMe M.2. Este equipo está valorado en
1\,800\texteuro. La vida útil de este activo es de 3 años.

Además, para hacer la aplicación accesible a todo el mundo, se ha adquirido un
servidor para ello (supuesto considerado). Este servidor está compuesto por dos
AMD EPYC, 8 GB de memoria RAM y 80gb de SSD. El equipo está valorado en
1\,300\texteuro. La vida útil de este activo es de 3 años.

Teniendo en cuenta que la duración del proyecto es de 5 meses, el cálculo de la
amortización se realiza de la siguiente forma:

\begin{figure}[H]
\begin{center}
$Amortización = \frac{Coste}{Vida~útil} \times \frac{5}{12}$
\end{center}
\caption{Cálculo de la amortización para este proyecto}
\end{figure}


En la tabla~\ref{tabla:hardware} se presentan los costes de estos activos y el
coste amortizado de los mismos.

\begin{table}[H]
    \centering
\begin{tabular}{lrr}
\toprule
\textbf{Activo}      & \textbf{Coste (€)}      & \textbf{Coste amortizado (€)}      \\ \midrule
Equipo sobremesa     & 1\,800                    & 250                      \\
Servidor             & 1\,300                    & 180,55                      \\ \midrule
\textbf{Total}       & 3\,100                    & 430,55                      \\ \midrule
\end{tabular}
\caption{Costes del hardware}
\label{tabla:hardware}
\end{table}


\textbf{Software}:

Para el desarrollo del producto se ha hecho uso de \textit{software}. En la
medida de lo posible se han utilizado licencias gratuitas y/o proporcionadas por
pertenecer a la Universidad de Burgos.

Los activos software que han supuesto un coste para la empresa es la adquisición
del sistema operativo Windows 10 Pro del equipo de sobremesa. Está valorado en
250\texteuro. Para el cálculo de la vida útil, se tiene en cuenta la
finalización del soporte de Microsoft el 14 de octubre de 2025, aproximadamente
dos años y medio.

El coste amortizado será 41,66\texteuro~(aplicando el mismo cálculo que antes).

\clearpage
\textbf{Costes indirectos}:

Se consideran unos gastos fijos indirectos iguales al 12\% del resto de gastos
anteriores. A estos se le añade otros gastos considerados.

\begin{table}[H]
    \centering
\begin{tabular}{lr}
\toprule
\textbf{Concepto}      & \textbf{Coste (€)}     \\ \midrule
Dominio <<dmacha.dev>>     & 12,00                    \\
12\% costes                & 1\,448,39                     \\ \midrule
\textbf{Total}       & 1\,460,39                     \\ \midrule
\end{tabular}
\caption{Costes indirectos}
\label{tabla:indirectos}
\end{table}


\textbf{Total}:

En la tabla~\ref{tabla:total} se presenta la suma de todos los costes descritos.

\begin{table}[H]
    \centering
\begin{tabular}{lr}
\toprule
\textbf{Tipo de coste}     & \textbf{Coste (€)}     \\ \midrule
Empleados                  & 11\,597,70               \\
Hardware                   & 430,55                     \\
Software                   & 41,66                     \\
Indirectos                 & 1\,460,39                     \\ \midrule
\textbf{Total}             & 13\,530,30                     \\ \midrule
\end{tabular}
\caption{Coste total}
\label{tabla:total}
\end{table}

El coste total del proyecto, finalmente, es de 13\,530,30\texteuro.

\subsubsection{Beneficios}

La aplicación no está pensada para extraer beneficio con su uso. Se trata de una
aplicación de índole docente que permite el acceso completo a todos los
usuarios. Esto incluye las ventajas que un usuario registrado tiene sobre un
anónimo, este último puede adquirir dichas ventajas de forma gratuita
(registro).

\clearpage
\subsection{Viabilidad legal}

El estudio de la viabilidad legal se basa en las licencias de las
bibliotecas/librerías que se han utilizado en el desarrollo. A partir del
listado de estas, se estudiará la permisividad en conjunto para saber cuál es la
más restrictiva y seleccionar acordemente la de este proyecto.

\begin{table}[h!]
    \centering
    \begin{tabular}{lcl}
    \toprule
    \textbf{Librería}         & \textbf{Versión} & \textbf{Licencia}                        \\ \midrule
    \textit{pandas}           & 1.4.3            & BSD 3                                    \\
    \textit{Babel}            & 2.11.0           & BSD 3                                    \\
    \textit{Flask}            & 2.2.5            & BSD 3                                    \\
    \textit{flask-babel}      & 3.0.1            & BSD 3                                    \\
    \textit{Flask-SQLAlchemy} & 3.0.3            & BSD 3                                    \\
    \textit{Flask-Login}      & 0.6.2            & MIT                                      \\
    \textit{scikit-learn}     & 1.2.0            & BSD 3                                    \\
    \textit{numpy}            & 1.23.3           & BSD 3                                    \\
    \textit{scipy}            & 1.9.3            & BSD 3                                    \\
    \textit{setuptools}       & 65.5.1           & MIT                                      \\
    \textit{pytest}           & 7.2.0            & MIT                                      \\
    \textit{Werkzeug}         & 2.2.3            & BSD 3                                    \\
    \textit{matplotlib}       & 3.7.1            & PSF\tablefootnote{Python
    Software Foundation License. A afectos prácticos solo conlleva realizar un
    pequeño resumen de lo que se ha modificado (y solo en caso de
    modificación/adición)~\cite{psf}.} \\
    \textit{WTForms}          & 3.0.1            & BSD 3                                    \\
    \textit{Flask-WTF}        & 1.1.1            & BSD 3                                    \\
    \textit{SQLAlchemy}       & 2.0.13           & MIT                                      \\
    \textit{sslearn}          & 1.0.3.1          & BSD 3                                    \\
    \textit{imbalanced-learn} & 0.10.1           & MIT                                      \\
    \textit{gunicorn}         & 20.1.0           & MIT                                      \\
    \textit{Bootstrap}        & 5.2.3            & MIT                                      \\
    \textit{D3js}             & 7.8.4            & ISC\tablefootnote{Internet Systems Consortium, equivalente a MIT.}                 \\
    \textit{jQuery}           & 3.6.4            & MIT                                      \\
    \textit{DataTables}       & 1.13.4           & MIT                                      \\ \bottomrule
    \end{tabular}%
    \caption{Bibliotecas usadas, versiones y licencias}
\end{table}

\imagen{anexos/planproyecto/Licencias}{Permisividad de las licencias.}

Para tener cierto contexto, en la figura~\ref{fig:anexos/planproyecto/Licencias}
se representan las licencias organizadas según las restricciones que imponen.
Una anchura mayor representa mayores libertades. Se debe tener en cuenta que
solo es una representación para determinar la licencia más restrictiva, es
decir, no es una representación calculada con exactitud.

La peculiaridad de \textit{BSD 3-Clause} es que incluye la cláusula de <<no
respaldo>>. Esta cláusula impide promocionar un producto con el nombre de la
organización o de sus colaboradores (que han creado el software usado). Es por
ello que su permisividad se ha considerado algo menor.

\paragraph{Selección}
Para seleccionar la licencia apropiada a este proyecto se tiene en cuenta que
incluir una licencia menos restrictiva que \texttt{BSD 3-Clause} podría
incumplir alguna de las <<cláusulas>> que esta impone. Por tanto, para mantener
esas normas y condiciones impuestas, el proyecto tendrá la licencia \textbf{BSD
3-Clause}.

\paragraph{Implicaciones de BSD 3-clause} Esta licencia tiene las siguientes implicaciones
(traducción no oficial)~\cite{bsd}:\\

    Copyright (c) 2023, David Martínez Acha
\begin{enumerate}
    \item Las redistribuciones del código fuente deben conservar el aviso de
    derechos de autor anterior, esta lista de condiciones y el siguiente
    descargo de responsabilidad.
    \begin{verbatim}
        ESTE SOFTWARE ES PROPORCIONADO POR LOS TITULARES 
        DE LOS DERECHOS DE AUTOR Y LOS CONTRIBUYENTES 
        <<TAL CUAL>> Y CUALQUIER GARANTÍA EXPLÍCITA O
        IMPLÍCITA, INCLUYENDO, ENTRE OTRAS, LAS GARANTÍAS
        IMPLÍCITAS DE COMERCIABILIDAD E IDONEIDAD PARA 
        UN PROPÓSITO EN PARTICULAR. EN NINGÚN CASO EL 
        TITULAR DE LOS DERECHOS DE AUTOR O LOS 
        CONTRIBUYENTES SERÁN RESPONSABLES POR CUALQUIER 
        DAÑO DIRECTO, INDIRECTO, INCIDENTAL, ESPECIAL, 
        EJEMPLAR O CONSECUENTE (INCLUYENDO, ENTRE OTROS, 
        LA ADQUISICIÓN DE BIENES O SERVICIOS SUSTITUTOS;
        PÉRDIDA DE USO, DATOS O BENEFICIOS; O 
        INTERRUPCIÓN DEL NEGOCIO) CUALQUIER CAUSA Y 
        SOBRE CUALQUIER TEORÍA DE RESPONSABILIDAD, YA 
        SEA POR CONTRATO, RESPONSABILIDAD ESTRICTA O 
        AGRAVIO (INCLUYENDO NEGLIGENCIA O DE OTRO TIPO)
        QUE SURJA DE CUALQUIER MANERA DEL USO DE ESTE 
        SOFTWARE, INCLUSO SI SE ADVIERTE DE LA 
        POSIBILIDAD DE DICHO DAÑO.
    \end{verbatim}
    \item Las redistribuciones en forma binaria deben reproducir el aviso de
    derechos de autor anterior, esta lista de condiciones y el siguiente
    descargo de responsabilidad en la documentación y/u otros materiales
    provistos con la distribución.
    \item Ni el nombre del titular de los derechos de autor ni los nombres de
    sus colaboradores pueden utilizarse para respaldar o promocionar productos
    derivados de este software sin el permiso previo por escrito.
\end{enumerate}

En general, resulta una licencia adecuada que brinda muchas libertades y dado el
enfoque docente, es lo que se busca.