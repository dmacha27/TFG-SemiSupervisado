\apendice{Especificación de diseño}

\section{Introducción}

En esta sección se van a describir las decisiones de diseño tomadas para llevar
a cabo todos los objetivos y requisitos iniciales establecidos. Se presentará el
formato que se utiliza para tratar los datos, cuál es el procedimiento interno
que realiza la Web para ofrecer al usuario las visualizaciones y cómo se traduce
todo ello en la arquitectura subyacente.

\section{Diseño de datos}

\subsection{Información de entrenamiento de los algoritmos}

Dado que el proyecto maneja dos fuentes de datos claras (por un lado los
algoritmos y por otro la base de datos), esta sección se ha separado del mismo
modo para explicar cada una de las partes: la información de entrenamiento y las
entidades utilizadas en base de datos.

\label{datos:entrenamiento}
Todas las visualizaciones de los algoritmos se nutren del proceso de
entrenamiento. Es decir, se tuvo que diseñar una forma de aglutinar la
información que ocurre durante este proceso.

Para adelantar un poco el funcionamiento de la web, todos estos datos son
transformados a JSON, el formato de texto con la sintaxis de JavaScript que
resulta muy sencillo para el intercambio de datos. Además, a la hora de trabajar
con ello en dicho lenguaje, se hace de forma directa (como diccionarios en otros
lenguajes de programación).

Pero antes de esa transformación, todos los datos son generados en Python. La
estructura de datos por excelencia para almacenar muchos datos (gracias a su
multitud de opciones) son los <<DataFrames>>. Toda la información que generan
los algoritmos son de este tipo.

Cada algoritmo retorna varios de estos <<DataFrame>>, al menos uno del proceso
de etiquetado y otro con las estadísticas generales. En el caso de
\textit{Democratic Co-Learning} y \textit{Tri-Training}, estos además retornan
los de las estadísticas específicas de cada clasificador base.

\subsubsection{Etiquetas}
Este <<DataFrame>> contiene todas las operaciones en las que los clasificadores
han añadido nuevas etiquetas a instancias no etiquetadas. Por lo general
indicarán los momentos en los que fueron etiquetadas (iteración) y el valor de
las mismas.

\paragraph{Self-Training}
Este formato sirve como base para todos los siguientes. Es una idea muy sencilla
(pues \textit{Self-Training} también lo es). 

La estructura de datos contendrá múltiples filas, cada una representa cada
instancia de todo el conjunto de datos de entrenamiento. Lo que se entiende por
conjunto de entrenamiento es, todos los datos etiquetados de los que aprenderá
el clasificador base junto con los no etiquetados.

Ahora bien, la información útil que permitirá saber los momentos de
clasificación y/o etiquetas estarán en las columnas:

\begin{itemize}
    \item Columnas con los nombres de los atributos de las instancias. Por
    ejemplo, para el famoso conjunto de datos \texttt{Iris} se tendrán 4
    columnas (una por cada atributo, \textbf{no se incluye la clase}):
    <<\textit{sepal length}>>, <<\textit{sepal width}>>, <<\textit{petal
    length}>> y <<\textit{petal width}>>.
    \item Columna <<iter>>: Por cada fila, representa el número de la iteración
    en la que esa instancia fue clasificada. Si por el criterio de parada no
    llega a ser clasificada corresponderá con el número de iteraciones final +
    1. Es decir, si en la iteración 9 el entrenamiento finalizó, corresponderá
    con 10. Obviamente, si la instancia es un dato inicial tendrá como iteración
    0.
    \item Columna <<target>>: Representa la etiqueta de la instancia. Es
    importante destacar que esta siempre será de tipo entero. Esto es porque en
    pasos previos se eliminan los valores nominales (no están permitidos). Si
    tampoco llega a ser clasificado, corresponderá con <<-1>>.
\end{itemize}

En la tabla~\ref{tabla:dataframe-st} se muestra un ejemplo del formato para
Self-Training (entrenamiento finalizado en la iteración 9).
\begin{table}[H]
\begin{tabular}{rrrrrrr}
    & petal.length & petal.width & sepal.length & sepal.width & iter & target \\ \toprule
0   & 5.6          & 2.5         & 3.9          & 1.1         & 0    & 1      \\
1   & 6.1          & 2.8         & 4.0          & 1.3         & 0    & 2      \\
78  & 6.7          & 3.1         & 5.6          & 2.4         & 6    & 2      \\
79  & 6.8          & 3.2         & 5.7          & 2.5         & 7    & 1      \\
142 & 6.8          & 2.8         & 4.8          & 1.4         & 10   & -1    
\end{tabular}
\caption{Ejemplo de DataFrame de Self-Training}
\label{tabla:dataframe-st}
\end{table}

En la tabla~\ref{tabla:dataframe-st} se puede ver un extracto de lo que podría
ser una ejecución. Las columnas de los atributos, la iteración (con iteración 10
para denotar que no fue etiquetado) y la etiqueta o \textit{target} (con -1 para
los que no fueron etiquetados).

\paragraph{Co-Training}
Es muy similar a \textit{Self-Training} salvo que este algoritmo concreto
utiliza dos clasificadores base. La consecuencia de esto a nivel del formato es
que se necesita almacenar cuál de los dos clasificadores clasifica cada
instancia. Pero más allá de esto, es el mismo formato.

Recopilando, las columnas para el <<DataFrame>> de \textit{Co-Training} son:
\begin{itemize}
    \item Columnas con los nombres de los atributos de las instancias.
    \item Columna \texttt{iter}.
    \item Columna \texttt{target}.
    \item Columna \texttt{clf}: Esta nueva columna indica el clasificador que le
    dio el valor  a la etiqueta. Por convención (necesaria para otros procesos
    en Web) es que si el dato es inicial, \texttt{clf} valdrá <<inicio>>, si es
    un dato clasificado durante el proceso valdrá
    <<CLF(\textit{nombre\_clasificador})>> donde \textit{nombre\_clasificador}
    será el extraído de \textit{Scikit-Learn}. Si no llega a ser clasificado
    valdrá -1.
\end{itemize}

En la tabla~\ref{tabla:dataframe-ct} se muestra un ejemplo del formato para
Co-Training (entrenamiento finalizado en la iteración 9).
\begin{table}[H]
    \resizebox{\textwidth}{!}{%
\begin{tabular}{rrrrrrrl}
    & petal.length & petal.width & sepal.length & sepal.width & iter & target & clf \\ \toprule
0   & 5.6          & 2.5         & 3.9          & 1.1         & 0    & 1  & inicio    \\
1   & 6.1          & 2.8         & 4.0          & 1.3         & 0    & 2  & inicio     \\
78  & 6.7          & 3.1         & 5.6          & 2.4         & 6    & 2  & CLF(SVC)    \\
79  & 6.8          & 3.2         & 5.7          & 2.5         & 7    & 1  & CLF(GaussianNB)     \\
142 & 6.8          & 2.8         & 4.8          & 1.4         & 10   & -1 & -1    
\end{tabular}
    }
    \caption{Ejemplo de DataFrame de Co-Training}
    \label{tabla:dataframe-ct}
\end{table}


\paragraph{Democratic Co-Learning}
Tomando como base Co-Training, este algoritmo no añade ninguna columna más (ni
elimina), solo modifica las existentes. Concretamente, las tres últimas columnas
(<<iter>>,<<target>> y <<clf>>) que estaban en singular ahora pasan a plural:
<<iters>>,<<targets>> y <<clfs>>. 

La razón es simplemente para mantener una lógica y semántica interna, este
algoritmo <<comparte>> las instancias entre tres clasificadores base. Cada uno
de ellos puede clasificar cada instancia, incluso con distintas etiquetas y en
la misma iteración que los otros clasificadores. Por lo tanto, para cada una de
estas columnas y para cada instancia se tendrá ahora una lista.

Recopilando, las columnas para el <<DataFrame>> de Democratic Co-Learning son:

\begin{itemize}
    \item Columnas con los nombres de los atributos de las instancias.
    \item Columna \texttt{iters}: Lista con la iteración en la que cada
    clasificador etiqueta la instancia. En el caso de un dato inicial, esta
    lista solo tendrá una posición y contendrá 0 (\texttt{[0]}), para el resto
    siempre tendrá tres posiciones (por los tres clasificadores base). Para este
    último caso cada posición es independiente, es decir, si un clasificador
    base no ha etiquetado, contendrá -1 (\textbf{diferencia con los
    anteriores}\footnote{La razón de que se indique -1 en vez de número de
    iteraciones + 1, es porque toda esta estructura se genera antes del
    entrenamiento. En los algoritmos anteriores, si quedaba alguna sin
    etiquetar, se añadía al final y se sabía el número de iteraciones final.}),
    pero para esa misma instancia otro clasificador base sí que puede haber
    etiquetado y contendrá dicha iteración (por ejemplo: $[-1,4,-1]$)
    \item Columna \texttt{targets}: Exactamente igual a <<iters>> salvo que no indica
    la iteración, sino la etiqueta que asigna el clasificador base. De nuevo, si
    no asigna una, su posición contendrá -1.
    \item Columna \texttt{clfs}: Hasta ahora se ha hablado de posiciones en las
    dos columnas anteriores. Para saber a qué clasificador se refieren esas
    posiciones, esta columna contiene otra lista con los tres nombres de los
    clasificadores. Si es un dato inicial, contendrá [inicio], en otro caso
    contendrá algo como \texttt{[CLF1(KNeighborsClassifier),
    CLF2(DecisionTreeClassifier), CLF3(GaussianNB)]}.
\end{itemize}

En la tabla~\ref{tabla:dataframe-dcl} se muestra un ejemplo del formato para
Democratic Co-Learning (entrenamiento finalizado en la iteración 9)\footnote{Se
han acortado los nombres de los clasificadores [CLF1, CLF2, CLF3], debería ser
[CLF1(KNeighborsClassifier), CLF2(DecisionTreeClassifier), CLF3(GaussianNB)]}:
\begin{table}[H]
    \resizebox{\textwidth}{!}{%
\begin{tabular}{rrrrrlll}
    & petal.length & petal.width & sepal.length & sepal.width & iter & target & clf \\ \hline
0   & 5.6          & 2.5         & 3.9          & 1.1         & [0]    & [1]  & [inicio]    \\
1   & 6.1          & 2.8         & 4.0          & 1.3         & [0]   & [2]  & [inicio]     \\
78  & 6.7          & 3.1         & 5.6          & 2.4         & [1, 4, -1]  & [2, 2, -1]  & [CLF1, CLF2, CLF3]    \\
79  & 6.8          & 3.2         & 5.7          & 2.5         & [-1, 2, -1]    & [-1, 1, -1]  & [CLF1, CLF2, CLF3]     \\
142 & 6.8          & 2.8         & 4.8          & 1.4         & [-1, -1, -1]   & [-1, -1, -1] & [CLF1, CLF2, CLF3]    
\end{tabular}
    }
    \caption{Ejemplo de DataFrame de Democratic Co-Learning}
    \label{tabla:dataframe-dcl}
\end{table}


\paragraph{Tri-Training}
Tomando la idea de Democratic Co-Learning, en este algoritmo también se tienen
tres clasificadores que pueden clasificar individualmente cada instancia. Sin
embargo, cada iteración, el conjunto de datos \textbf{nuevos} etiquetados se
vacía. Es decir, en una iteración se acaban etiquetando algunos, pero al
principio de la siguiente se vacía ese conjunto y se vuelven a etiquetar de
nuevo.

Entonces, el mecanismo de las listas de Democratic Co-Learning no funcionaría.
Se debe añadir un nivel más de registro. Simplemente con añadir una lista en
cada posición de las listas de <<iters>> y <<targets>> ya se puede registrar
todos los momentos en los que una instancia se etiqueta (de nuevo, cada
instancia podría ser etiquetada dos o más veces por un mismo clasificador base,
al contrario del anterior).


Recopilando, las columnas para el <<DataFrame>> de Tri-Training son:

\begin{itemize}
    \item Columnas con los nombres de los atributos de las instancias.
    \item Columna <<iters>>: Lista de listas con la iteración en la que cada
    clasificador etiqueta la instancia. En el caso de un dato inicial, esta
    lista sol o tendrá una posición y contendrá 0 (\texttt{[0]}), para el resto
    siempre tendrá una lista en las tres posiciones (por los tres clasificadores
    base). Para esto último caso las posiciones siguen siendo independientes
    solo que ahora si no se etiqueta la lista estará vacía (por ejemplo, las
    iteraciones de un dato podrían ser: \texttt{[[2], [], []]}, los dos últimos
    clasificadores no etiquetaron esa instancia en ningún momento). Para
    clarificar lo comentado anteriormente, los clasificadores podrían etiquetar
    una misma instancia dos o más veces (por ejemplo: \texttt{[[2], [2], [1,
    2]]}, el último clasificador etiquetó la instancia en dos ocasiones).
    \item Columna <<targets>>: Exactamente igual a <<iters>> salvo que no indica
    la iteración, sino la etiqueta que asigna el clasificador base. Y de nuevo,
    si un clasificador no etiqueta en ningún momento esa instancia su lista
    interna estará vacía (por ejemplo: \texttt{[[2], [], [2]]}).
    \item Columna <<clfs>>: No se modifica respecto a Co-Training, contiene la
    lista de los nombres de los tres clasificadores.
\end{itemize}

En la tabla~\ref{tabla:dataframe-tt} se muestra un ejemplo del formato para
Tri-Training (entrenamiento finalizado en la iteración 9)\footnote{Se han
acortado los nombres de los clasificadores [CLF1, CLF2, CLF3] debería ser
[CLF1(KNeighborsClassifier), CLF2(DecisionTreeClassifier), CLF3(GaussianNB)]}:
\begin{table}[H]
    \resizebox{\textwidth}{!}{%
\begin{tabular}{rrrrrlll}
    & petal.length & petal.width & sepal.length & sepal.width & iter & target & clf \\ \hline
0   & 5.6          & 2.5         & 3.9          & 1.1         & [0]    & [1]  & [inicio]    \\
1   & 6.1          & 2.8         & 4.0          & 1.3         & [0]   & [2]  & [inicio]     \\
78  & 6.7          & 3.1         & 5.6          & 2.4         & [[1], [1,2], [~]]  & [[2], [2, 2], [~]]  & [CLF1, CLF2, CLF3]    \\
79  & 6.8          & 3.2         & 5.7          & 2.5         & [[~], [2], [~]]    & [[~], [1], [~]]  & [CLF1, CLF2, CLF3]     \\
142 & 6.8          & 2.8         & 4.8          & 1.4         & [[~], [~], [~]]   & [[~], [~], [~]]  & [CLF1, CLF2, CLF3]    
\end{tabular}
    }
    \caption{Ejemplo de DataFrame de Tri-Training}
    \label{tabla:dataframe-tt}
\end{table}

\paragraph{Interpretación sencilla de estos formatos} Cuando se realiza su
visualización, el primer paso es extraer los datos. Lo que se hace es crear un
punto en el gráfico por cada instancia, con la particularidad de que cuando se
entra en los algoritmos Democratic Co-Learning o Tri-Training, se añade más de
un punto por cada instancia, representando la individualidad de cada
clasificador base (cada uno de ellos puede haber clasificado esa instancia por
separado e incluso más de una vez).

Cuando se genera el gráfico con sus puntos, cada punto lleva guardada la
información de las iteraciones, etiquetas y clasificadores. Así se controla
cuándo ocultar/colorear/mostrar un punto. Por ejemplo, cuando se navega a la
siguiente iteración se filtran todos los puntos que tenga esa iteración en la
columna <<iter>> (o <<iters>>). Obviamente, cada algoritmo tiene sus
particularidades, pero esta es la idea general.

\subsubsection{Estadísticas generales}
Las estadísticas generales son comunes a todos los algoritmos, no hay ninguna
modificación entre ellos.

Se tiene un <<DataFrame>> con tantas filas como iteraciones se han ejecutado. En
cuanto a las columnas, simplemente son los nombres de las estadísticas que se
desean mostrar. Los nombres son los que se mostrarán en la Web.

En la tabla~\ref{tabla:dataframe-generales} se presenta un ejemplo del formato
de las estadísticas generales.
\begin{table}
\centering
\begin{tabular}{llllll}
  & Accuracy  & Precision & Error    & F1\_score & Recall    \\ \hline
0 & 0.833333  & 0.888889  & 0.166667 & 0.822222  & 0.833333  \\
1 & 1.000000 & 1.000000 & 0.000000 & 1.000000 & 1.000000 \\
2 & 1.000000 & 1.000000 & 0.000000 & 1.000000 & 1.000000 \\
3 & 1.000000 & 1.000000 & 0.000000 & 1.000000 & 1.000000 \\
4 & 1.000000 & 1.000000 & 0.000000 & 1.000000 & 1.000000
\end{tabular}
\caption{Ejemplo de DataFrame de las estadísticas generales}
\label{tabla:dataframe-generales}
\end{table}

\subsubsection{Estadísticas específicas}
Este tipo de estadísticas se refiere a la necesidad de mostrar también las
estadísticas particulares de los clasificadores base. Esto aplica para
Co-Training, Democratic Co-Learning y Tri-Training.

El núcleo de esta estructura de datos siguen siendo los <<DataFrames>>, sin
embargo, se han envuelto en un diccionario. El diccionario tiene como claves
cada uno de los nombres de los clasificadores base de la ejecución (por ejemplo:
\texttt{CLF3(GaussianNB)})\footnote{En Co-Training nunca podría llegar a ser
<<CLF3>> pues solo hay dos clasificadores, pero es la misma idea}. Los valores
del diccionario serán esos <<DataFrames>> que son exactamente iguales que para
las estadísticas generales. Guardarán por cada iteración (fila), las
estadísticas (columnas) para el clasificador base concreto (el de la clave).

\subsection{Base de datos}

El diagrama general E/R se puede ver en la figura~\ref{fig:anexos/diseño/ER}.
Para el manejo de toda la información que se ha necesitado en el flujo de la
aplicación, se han creado las siguientes entidades:

\begin{itemize}
    \item \textbf{Usuario} (User): Representa al usuario registrado en la
    aplicación. Contiene un identificador que representa la clave primaria. Los
    datos personales de los usuarios que guarda la entidad son: email (único en
    toda la base de datos), el nombre y la contraseña (cifrada mediante
    SHA-256). Aparte de estos, también se guarda el último inicio de sesión y un
    campo que indica si el usuario es administrador.

    Por último, un usuario puede tener varios ficheros y varias ejecuciones.
    Esto está ejemplificado mediante dos relaciones a las otras dos entidades
    siguientes (relaciones \texttt{One-To-Many}).

    \item \textbf{Dataset}: Representa un fichero subido por el usuario.
    Contiene un identificador que representa la clave primaria. Como datos
    propios del fichero, contiene el nombre del mismo (tal y como se guarda en
    el sistema) y la fecha de subida. 

    Esta entidad mantiene una clave foránea al usuario (el identificador del
    usuario) junto con una referencia directa a él (aspecto interno de
    \textit{SQLAlchemy} para poder acceder al usuario sin realizar consulta).

    \item \textbf{Run}: Representa la ejecución de un algoritmo. Contiene un
    identificador que representa la clave primaria. Como datos propios de una
    ejecución contiene:
    \begin{itemize}
        \item El nombre del algoritmo.
        \item La cadena de caracteres (JSON) con todos los parámetros.
        \item El nombre del fichero con el que se ejecutó (conjunto de datos).
        \item La fecha de ejecución.
        \item Componente $X$.
        \item Componente $Y$.
        \item Nombre del fichero del sistema que guarda todos los datos de la ejecución.
    \end{itemize}

    Esta entidad también mantiene una clave foránea al usuario (el identificador
    del usuario) junto con una referencia directa a él (aspecto interno de
    \textit{SQLAlchemy} para poder acceder al usuario sin realizar consulta).
\end{itemize}

\begin{landscape}
\subsubsection{Diagrama Entidad/Relación}
\imagencontamano{anexos/diseño/ER}{Diagrama Entidad/Relación}{1.5}
\end{landscape}

\subsubsection{Diagrama relacional}
\imagen{anexos/diseño/Tablas}{Diagrama relacional}
\section{Diseño procedimental}
En esta sección se incluyen los diagramas de secuencia considerados para
explicar la interacción del usuario con la aplicación (el procedimiento
seguido).

Concretamente, la interacción principal de la aplicación consiste en la
visualización de un algoritmo. El diagrama de secuencia de dicho proceso puede
verse en la figura~\ref{fig:anexos/diseño/ProcedimientoWeb}. Esta interacción
puede resumirse en:

\begin{enumerate}
    \item El usuario accede a la aplicación y selecciona un algoritmo. Por su
    parte, el servidor, establecerá que el usuario lo ha seleccionado.
    \item El usuario carga un conjunto de datos que el servidor almacena y le
    permite al usuario configurar el algoritmo.
    \item El usuario introduce los parámetros del algoritmo (propios del
    algoritmo y de la visualización).
    \item El navegador realizará una petición con todos esos parámetros a la
    espera de obtener una respuesta. Mientras ocurre, el servidor se encarga de
    instanciar el algoritmo, ejecutarlo y enviar los resultados al navegador.
    \item El navegador (mediante JavaScript) interpretará los datos y brindará
    las visualizaciones al usuario.
\end{enumerate}

\imagencontamano{anexos/diseño/ProcedimientoWeb}{Diagrama de secuencia de la visualización de un algoritmo}{1.1}

\section{Diseño arquitectónico}

Adelantando el contenido de este apartado, la arquitectura seguida en el
desarrollo del software es la arquitectura de tres capas. Sin embargo, esta
arquitectura tiene como punto de partida la arquitectura
\emph{cliente-servidor}.

La arquitectura cliente-servidor es un modelo de diseño en el que las tareas se
reparten entre los servidores (proveedores) y los clientes
(demandantes)~\cite{eswiki:149310099}. De hecho, como en principio solo tienen
estos dos elementos, suele referirse a veces como arquitectura de dos capas.

La separación entre ambos elementos es lógica y además el servidor no tiene por
qué ser una única máquina. Y aquí es donde entran en juego los cimientos de la
arquitectura de tres capas. Una disposición muy utilizada de cliente-servidor
son los sistemas multicapa, en ellos, el servidor se descompone en más elementos
(mayor desacoplamiento).

\subsection{Arquitectura de tres capas}

Estas tres capas o niveles son: capa de presentación, capa de aplicación o de
negocio y la capa de datos. En la figura
~\ref{fig:anexos/diseño/ArquitecturaNormal} se representa un diagrama de este
tipo de arquitectura.

\imagen{anexos/diseño/ArquitecturaNormal}{Arquitectura de tres capas.}


\begin{itemize}
    \item \textbf{Capa de presentación}: es la capa con la que se presenta el
    sistema y el usuario interactúa. Muestra la información al usuario y además
    recopila información de este. Esta capa es la que ejecuta el navegador Web
    desde el que accede el usuario~\cite{arq3capas:ibm}. Se conoce también como
    interfaz gráfica (del sistema). Esta capa se comunica exclusivamente con la
    capa de negocio~\cite{eswiki:149121324}.

    En el proyecto, esta capa está implementada mediante todas las plantillas,
    estilos (CSS) y código JavaScript con todos los formularios, enlaces,
    botones y visualizaciones. Concretamente, esto es generado por el
    <<framework>> Flask (este <<framework>> puede verse en este caso como la
    capa de presentación). Toda esta capa se nutre de la información que
    solicita a la capa de negocio (por ejemplo, los datos de las ejecuciones, no
    son generados por la capa de presentación sino por esta última). 
\end{itemize}

La comunicación entre la capa anterior y la siguiente se realiza mediante el
protocolo HTTP (los conceptos pueden encontrarse en la memoria) añadiendo la
segurización del mismo (HTTPS) para cifrar los mensajes. Aquí aparece el
concepto de API, que define cómo se comunica el navegador con el servidor. En el
proyecto actual se está utilizando una API por así decirlo, <<privada>>, en el
sentido de que no está pensada para ser accedida por todos los usuarios, sino
solo los que estén manejando la aplicación y en el flujo de la misma. 

\begin{itemize}
    \item \textbf{Capa de negocio}: es el núcleo de la aplicación, se encarga de
    manejar las peticiones del usuario desde la capa de presentación y de enviar
    las respuestas correspondientes. Su nombre reside en que aquí se define la
    lógica empresarial (qué es lo que hace la aplicación). También se comunica
    con la capa de datos para almacenar o recuperar información.

    En el proyecto, esta capa está implementada en Python en el código de cada
    ruta accedida. Es decir, las peticiones que realiza el usuario serán
    manejadas por las rutas correspondientes, realizando el procesamiento
    adecuado (el negocio). Por ejemplo, la ejecución de un algoritmo dados sus
    parámetros para retornar los datos de la ejecución o el registro de un nuevo
    usuario.
\end{itemize}

La comunicación entre la capa anterior y la siguiente se realiza mediante DB-API
(Python Database API). No es un protocolo como tal, sino un conjunto de clases y
funciones para el acceso a múltiples bases de datos (MySQL, SQLite,
PostgreSQL...). Además, no se está utilizando directamente, sino que se hace uso
de <<SQLAlchemy>>, que oculta el manejo de todas esas funciones y lo hace mucho
más simple. Dependiendo del dialecto de la base de datos, cuando se intenta
acceder a una base de datos, se establecerá lo que se llama una <<conexión
DBAPI>>.

\begin{itemize}
    \item \textbf{Capa de datos}: conocida también como nivel de base de datos o
    nivel de acceso, almacena y gestiona el acceso a los datos. Por lo general
    esta capa es un sistema de gestión de base de datos como MySQL, PostgreSQL,
    Oracle...
\end{itemize}


En el proyecto actual se está utilizando SQLite, una biblioteca que implementa
un motor de base de datos. Actúa por sí mismo como si fuera un servidor
independiente~\cite{sqlite} (simulando lo que hacen otras bases de datos), pero
completamente acoplado a la aplicación (en local). Es decir, no se crea como en
otras bases de datos (MySQL), un proceso o instancia separada de la aplicación
(que incluso suele estar en otro servidor). La base de datos SQLite es un <<todo
en uno>> que se encuentra en la misma estructura de la aplicación, almacenada
como un archivo único. Desde el punto de vista de la aplicación (capa de
negocio) esto no tiene relevancia y actúa de la misma forma que con otros
gestores.

Por todo esto, el esquema de la arquitectura de tres capas podría ahora verse
como en la figura~\ref{fig:anexos/diseño/ArquitecturaVASS}.

\imagen{anexos/diseño/ArquitecturaVASS}{Arquitectura de tres capas.}

Siguen apareciendo las tres capas propias de la arquitectura, pero con la
particularidad de que no se tiene un servidor dedicado para la base de datos.

\clearpage
\subsection{Diagrama de componentes y despliegue}
En el diagrama~\ref{fig:anexos/diseño/DiagramaComponentes} es una simplificación
de los componentes que intervienen en la aplicación. Se ha abstraído la
aplicación como un todo, es conveniente visualizar el diagrama de despliegue
(ver figura~\ref{fig:anexos/diseño/DiagramaDespliegue}).
\imagencontamano{anexos/diseño/DiagramaComponentes}{Diagrama de componentes.}{0.65}

\imagencontamano{anexos/diseño/DiagramaDespliegue}{Diagrama de despliegue.}{0.6}

\section{Diseño Web}

\subsection{Primer \textit{mockup} o maqueta} 

Se presenta el primer \textit{mockup} o maqueta que se comentó de la página web.
Todas las páginas tendrían una base común en la que aparecerá información
general como la Universidad de Burgos (barra superior).

\imagen{anexos/diseño/MUP_Inicio}{Página inicial de la Web.}

En esta página inicial el usuario podrá seleccionar el algoritmo que desea
visualizar. En los cuadrados existirá un logo o imagen representativa del
algoritmo junto con su nombre.

\imagen{anexos/diseño/MUP_ConfAlgoritmo}{Página de configuración del algoritmo.}

En esta ventana el usuario podrá subir el conjunto de datos que desee o incluso
seleccionar alguno de los almacenados localmente. Además, como los algoritmos
tienen parámetros personalizables también habrá elemento para configurarlos.

Antes de iniciar, se muestra una explicación del algoritmo general y su
pseudocódigo.


\imagen{anexos/diseño/MUP_Algoritmo}{Página de ejecución del algoritmo.}

Mostrará la evolución del entrenamiento de los algoritmos con una vista
principal (izquierda) de la clasificación y un compendio de métricas como la
precisión o el error en su caso (derecha). Esto último principalmente planteado
para ocultar/ver lo que el usuario desee en cada momento.

\subsection{Diseño de Usuarios}

\imagen{anexos/diseño/MUP_NAVBAR}{Barra de navegación principal}
\imagen{anexos/diseño/MUP_NAVBAR_LOGGED}{Barra de navegación con usuario}
\imagen{anexos/diseño/MUP_NAVBAR_HOVER}{Animación <<hover>> en barra de navegación}
\imagen{anexos/diseño/MUP_MIESPACIO}{Espacio personal del usuario}
\imagen{anexos/diseño/MUP_PERFIL}{visualización del perfil y modificación}