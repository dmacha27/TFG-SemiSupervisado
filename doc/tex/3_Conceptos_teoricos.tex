\capitulo{3}{Conceptos teóricos}

En esta sección se presentarán los principales conceptos teóricos del proyecto.
Estos incluyen el aprendizaje automático y más específicamente el aprendizaje
semi-supervisado.

\section{Aprendizaje automático}

Según \cite{intelligent:ml}, el aprendizaje automático (\textit{machine
learning}) es una rama de la Inteligencia artificial como una técnica de
análisis de datos que enseña a las computadoras a aprender de la
\textbf{experiencia} (es decir, lo que realizan los humanos). Para ello, el
aprendizaje automático se nutre de gran cantidad de datos (o los suficientes
para el problema concreto) que son procesados por ciertos algoritmos. Estos
datos son ejemplos (también llamados instancias o prototipos), \cite{pascual:ml}
mediante los cuales, los algoritmos son capaces de generalizar comportamientos
que se encuentran ocultos. 

La característica principal de estos algoritmos es que son capaces de mejorar su
rendimiento de forma automática basándose en procesos de entrenamiento y también
en las fases posteriores de explotación. Debido a sus propiedades, el
aprendizaje automático se ha convertido en un campo de alta importancia,
aplicándose a multitud de campos como medicina, automoción, visión
artificial\ldots Los tipos de aprendizaje automático se suelen clasificar en los
siguientes: aprendizaje supervisado, aprendizaje no supervisado y aprendizaje
por refuerzo. Sin embargo, aparece una nueva disciplina que se encuentra a
caballo entre el supervisado y no supervisado (utiliza tanto datos etiquetados
como no etiquetados para el entrenamiento) \cite{vanEngelen2020}.

En la figura \ref{fig:taxonomia} se puede ver una
clasificación de aprendizaje automático.

\imagen{taxonomia}{Clasificación de aprendizaje automático \cite{neova:taxonomy}.}{1}


\subsection{Aprendizaje supervisado}

El aprendizaje supervisado es una de las aproximaciones del aprendizaje
automático. Los algoritmos de aprendizaje supervisado son entrenados con datos
que han sido etiquetados para una salida concreta \cite{david:sl}. Por ejemplo,
dadas unas biopsias de pacientes, una posible etiqueta es si padecen de cáncer o
no. Estos datos tienen una serie de características (e.g. en el caso de una
biopsia se tendría la edad, tamaño tumoral, si ha tenido lugar mitosis o no...)
y todas ellas pueden ser binarias, categóricas o continuas \cite{salim:sl}.

Es común que antes del entrenamiento, estos datos son particionados en: conjunto de
entrenamiento, conjunto de test o conjunto de validación. De forma resumida, el
conjunto de entrenamiento serán los datos que utilice el propio algoritmo para
aprender y generalizar los comportamientos ocultos de los mismos. El conjunto de
validación se utilizará para tener un control de que el modelo está
generalizando y no sobreajustando (memorizando los datos) y por último, el
conjunto de test sirve para estimar el rendimiento real que podrá tener el
modelo en explotación \cite{enwiki:conjuntos}. En la figura
\ref{fig:aprendizajesupervisado} puede visualizarse el funcionamiento general.

\imagen{aprendizajesupervisado}{Funcionamiento general del aprendizaje supervisado \cite{salim:sl}.}{1}

El aprendizaje supervisado está altamente influenciado por esto. Por un lado, si
las etiquetas son categóricas o binarias el modelo será de
\textbf{clasificación} y por otro, si las etiquetas son continuas el modelo será
de \textbf{regresión}.

\begin{itemize}
    \item \textbf{Clasificación}: Los algoritmos de clasificación, a veces
    denominados simplemente como clasificadores, tratan de predecir la clase de
    una nueva entrada a partir del entrenamiento previo realizado. Estas clases
    son discretas y en clasificación pueden referirse a clases (o etiquetas)
    binarias o clases múltiples.
    
    \item \textbf{Regresión}: En este caso, el algoritmo asigna un valor
    continuo a una entrada. Es decir, trata de encontrar una función continua
    basándose en las variables de entrada. Se denomina también ajuste de
    funciones.
\end{itemize}

\clearpage

\subsection{Aprendizaje no supervisado}

A diferencia del aprendizaje supervisado, en el no supervisado, los algoritmos
no se nutren de datos etiquetados. En otras palabras, los usuarios no "<supervisan"> el modelo
\cite{salim:usl}. Esto quiere decir que no aprenderán de etiquetas, sino de la
propia estructura que se encuentre en los datos (patrones). Por ejemplo, dadas
unas imágenes de animales, sin especificar cuál es cuál, el aprendizaje no
supervisado identificará las similitudes entre imágenes y como resultado podría
dar la separación de las especies (o separaciones entre colores, pelaje,
raza...).

Como principales usos del aprendizaje no supervisado, suele aplicarse a:
\vspace{-4px}
\begin{enumerate}
    \item \textbf{Agrupamiento (Clustering)}: Este modelo de aprendizaje no
    supervisado trata de dividir los datos en grupos. Para ello, estudia las
    similitudes entre ellos y también en las disimilitudes con otros. Estos
    modelos pueden tanto descubrir por ellos mismos los "<clústeres"> o grupos
    que se encuentran o indicarle cuántos debe identificar \cite{salim:usl}.
    \item \textbf{Reducción de la dimensionalidad}: Para empezar, el término
    "<dimensionalidad"> hace referencia al número de variables de entrada que
    tienen los datos. En la realidad, los conjuntos de datos sobre los que se
    trabaja suelen tener una dimensionalidad grande. Según
    \cite{javatpoint:reduccionsdims} la reducción de dimensionalidad se denomina
    como "<Una forma de convertir conjuntos de datos de alta dimensionalidad en
    conjunto de datos de menor dimensionalidad, pero garantizando que proporciona
    información similar">. Es decir, simplificar el problema pero sin perder
    toda esa estructura interesante de los datos. Algunos ejemplos pueden ser:
    \begin{itemize}
        \item Análisis de Componentes Principales (PCA)
        \item Cuantificación vectorial
        \item Autoencoders
    \end{itemize}
\end{enumerate}

\imagenconurl{clustering}{Clusters}{\footnotesize{Clusters. Ejemplo de
clustering, a la izquierda los datos no etiquetados y a la derecha los datos
coloreados según las clases identificadas por el algoritmo de clustering. By
hellisp - Own work, Public Domain,
\url{https://commons.wikimedia.org/w/index.php?curid=36929773}. }}{0.5} 
\subsection{Aprendizaje semi-supervisado}

Según \cite{vanEngelen2020}, el aprendizaje semi-supervisado es la rama del
aprendizaje automático referido al uso de datos tanto etiquetados como no
etiquetados simultáneamente para realizar tareas de aprendizaje. Se encuentra a
caballo  entre el aprendizaje supervisado y no supervisado. Concretamente, los
problemas donde más se aplica, y donde más investigación se realiza es en
clasificación. Los métodos semi-supervisados resultan especialmente útiles
cuando se tienen escasos datos etiquetados, que, aparte de ser una situación
común en problemas reales, el proceso de etiquetado es una labor compleja, que
consume tiempo y es costosa.

\subsubsection{Suposiciones}
El objetivo de usar datos no etiquetados es construir un clasificador que sea
mejor que el aprendizaje supervisado, en el que solo se tienen datos
etiquetados. Pero para que el aprendizaje semi-supervisado mejore a lo ya
existente, tiene una serie de suposiciones que han de cumplirse.

En primera instancia se dice que la condición necesaria es que la distribución
\textit{p(x)} del espacio de entrada contiene información sobre la distribución
posterior \textit{p(y|x)} \cite{vanEngelen2020}.

Pero la forma en el que interactúan los datos de una distribución y la posterior,
no siempre es la misma:

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Smoothness assumption}]
    Esta suposición indica que si dos ejemplos (o instancias) de la entrada
    están cerca en ese espacio de entrada, entonces, probablemente, sus
    etiquetas sean las mismas.
\end{tcolorbox}

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Low-density assumption}]
    Esta suposición indica que en clasificación, los límites de decisión deben
    encontrarse en zonas en las que haya pocos de estos ejemplos (o instancias).
\end{tcolorbox}

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Manifold assumption}]
    Los datos pueden tener una dimensionalidad alta (muchas características)
    pero generalmente no todas las características son completamente útiles. Los
    datos a menudo se encuentran en unas estructuras de más baja
    dimensionalidad. Estas estructuras se conocen como "<manifolds">. Esta
    suposición indica que si los datos del espacio de entrada se encuentran en
    estas "<manifolds"> entonces aquellos puntos que se encuentren en el mismo
    "<manifolds"> tendrán la misma etiqueta. \cite{towardsdatascience:semi,vanEngelen2020}
\end{tcolorbox}

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Cluster assumption}]
    Como generalización de las anteriores, aquellos datos que se encuentren en
    un mismo clúster tendrán la misma etiqueta.
\end{tcolorbox}


De estas suposiciones se extrae el concepto de "<similitud"> en el que en todas
ellas se encuentra presente. Y en realidad, todas son versiones de
\textit{Cluster assumption} en la que los puntos similares tienden a pertenecer
al mismo grupo. 

Además, la suposición de clúster resulta necesaria para que el aprendizaje
semi-supervisado mejore al supervisado. Si los datos no pueden ser agrupados,
entonces no mejorará ningún método supervisado~\cite{vanEngelen2020}.


Para tener un punto de vista general, en la figura \ref{fig:aprendizajesemisupervisado} se presenta la
taxonomía de los métodos de aprendizaje semi-supervisado.

\imagen{aprendizajesemisupervisado}{Taxonomía de métodos semi-supervisados
\cite{vanEngelen2020}.}{1}

El núcleo de este proyecto está basado en los métodos inductivos. Su idea es muy
sencilla y está altamente relacionada con el objetivo del aprendizaje
supervisado, trata de crear un clasificador que prediga etiquetas para datos
nuevos. Por lo tanto, los algoritmos construidos tendrán este objetivo, aunque
con un punto más de concreción: los métodos "<wrapper"> o de envoltura.

Los conocidos métodos "<wrapper"> se basan en el \textit{pseudo etiquetado}
("<pseudo-labelling">), es el proceso en el que los clasificadores entrenados
con datos etiquetados generan etiquetas para los no etiquetados. Una vez
completado este proceso, el clasificador se vuelve a entrenar pero añadiendo
estos nuevos datos. La gran ventaja que suponen estos métodos es que pueden
utilizarse con casi todos los clasificadores (supervisados) existentes
\cite{vanEngelen2020}.

\paragraph{Self-Training}
Se trata del método de aprendizaje semi-supervisado más sencillo y "<directo">.
Este método envuelve un único clasificador base, que entrena con los datos
etiquetados iniciales y aprovecha el proceso de pseudo etiquetado comentado para
continuar su entrenamiento.

El método comienza por entrenar ese clasificador con los datos etiquetados que
se tienen. A partir de este aprendizaje inicial, se etiqueta el resto de datos.
De todas las nuevas predicciones se seleccionan aquellas en las que el
clasificador más confianza tiene (de haber acertado). Una vez seleccionados, el
clasificador es reentrenado con la unión de los ya etiquetados y estos nuevos.
El proceso continúa hasta un criterio de parada (generalmente hasta etiquetar
todos los datos o un número máximo de iteraciones).

En este proceso, el paso más importante es la incorporación de nuevos datos al
conjunto de etiquetados porque, \textbf{probablemente}, la predicción sea la
correcta. Es importante entonces que el cálculo de la probabilidad se realice
correctamente para asegurar que los nuevos datos son de interés. En caso
contrario, no es posible aprovechar los beneficios que ofrece self-training~
\cite{vanEngelen2020}. Todo este proceso queda descrito en el algoritmo
\ref{pseudo:self-training}.

\begin{algorithm}
    \DontPrintSemicolon
    \KwIn{Conjunto de datos etiquetados \textbf{\textit{L}}, 
    no etiquetados \textbf{\textit{U}} y clasificador \textbf{\textit{H}}}
    \KwOut{Clasificador entrenado}
     \While{$|U| \neq 0$}{
        Entrenar \textbf{\textit{H}} con \textbf{\textit{L}}\;
        Predecir etiquetas de \textbf{\textit{U}}\;
        Seleccionar un conjunto \textbf{\textit{T}} con aquellos datos que tenga la mayor probabilidad\;
        $\textbf{\textit{L}} = \textbf{\textit{L}} \cup \textbf{\textit{T}}$\;
        $\textbf{\textit{U}} = \textbf{\textit{U}} - \textbf{\textit{T}}$\;
     }
     Entrenar \textbf{\textit{H}} con \textbf{\textit{L}}\;
     \textbf{return} \textbf{\textit{H}}
     \caption{Self-Training}\label{pseudo:self-training}
\end{algorithm}

Sobre esta base, el algoritmo tiene muchas formas de diseñarse. En algunos casos
la condición de parada suele tomarse como un número máximo de iteraciones.
También, la cantidad de datos que se incorporan al conjunto \textbf{L} (con
mayor confianza) puede ser fija, o mediante un límite mínimo de
confianza/probabilidad (todas las instancias con mayor probabilidad se
añadirían).

\paragraph{Co-Training}
Basado fuertemente en Self-Training, en este caso \textbf{varios} clasificadores
(normalmente dos) se encargan del proceso e <<interactúan>> entre sí. Del mismo
modo, una vez entrenados predicen las etiquetas de los no clasificados y todos
los clasificadores añaden las mejores predicciones (mayor
confianza/probabilidad).

En \cite{blum1998combining}, Blum y Mitchel propusieron el funcionamiento básico
de Co-Training con dos vistas sobre los datos (<<multi-view>>). Estas vistas
corresponden no con subconjuntos de las instancias, sino de subconjuntos de las
características de las mismas. Es decir, cada clasificador va a entrenarse
teniendo en cuenta características distintas. Idealmente estas vistas son
independientes y pueden predecir por sí solas la etiqueta (aunque no siempre se
cumplirá). Cuando los clasificadores predicen etiquetas sobre los datos, se
seleccionan de ambos los de mayor confianza y construyen el nuevo conjunto de
entrenamiento para la siguiente iteración.


\begin{algorithm}
    \DontPrintSemicolon
    \KwIn{Conjunto de datos etiquetados $\pmb{L}$, 
    no etiquetados $\pmb{U}$, clasificadores $\pmb{H}_1$
    y $\pmb{H}_2$, $p$ (positivos), 
    $n$ (negativos), $u$ (número de datos iniciales), $k$ (iteraciones)}
    \KwOut{Clasificadores entrenados}
    Crear un subconjunto $\pmb{U'}$ seleccionando $u$ instancias aleatorias de $\pmb{U}$\;
    \For{k iteraciones}{
        Entrenar $\pmb{H}_1$ con $\pmb{L}$
        solo considerando un subconjunto ($\pmb{x}_1$) de las características de cada instancia ($x$)\;
        Entrenar $\pmb{H}_2$ con $\pmb{L}$
        solo considerando el otro subconjunto ($\pmb{x}_2$) de las características de cada instancia ($x$)\;

        Hacer que $\pmb{H}_1$ prediga $p$ instancias positivas y $n$ negativas de $\pmb{U'}$ que tengan la mayor confianza\;
        Hacer que $\pmb{H}_2$ prediga $p$ instancias positivas y $n$ negativas de $\pmb{U'}$ que tengan la mayor confianza\;
        Añadir estas instancias seleccionadas a $\pmb{L}$\;
        Reponer $\pmb{U'}$ añadiendo $2p + 2n$ instancias de $\pmb{U}$\;
     }
     \Return{$\pmb{H}_1,\pmb{H}_2$}
     \caption{Co-Training}\label{pseudo:co-training}
\end{algorithm}

\clearpage
\paragraph{Democratic Co-Learning}

Yan Zhou y Sally Goldman presentaron en \cite{zhou2004democratic} un algoritmo
de aprendizaje semi-supervisado en la línea de Co-Training (varios
clasificadores). La diferencia sustancial es que no trabajan con dos (o más)
conjunto de atributos (para que cada clasificador utilice uno de ellos), en este
caso solo se tiene un único conjunto de atributos (<<single-view>>).

Partiendo de los datos etiquetados, varios clasificadores realizan votación
ponderada sobre los no etiquetados. Lo que quiere decir que, para una instancia,
su nueva etiqueta será la que vote la mayoría. Además, para aquellos
clasificadores que no votan como la mayoría, la instancia se añade a su conjunto
de entrenamiento junto a la etiqueta mayoritaria, de esta forma se <<obliga>> en
la siguiente iteración a aprenderla. Todo el proceso se repite hasta que no se
añadan más instancias a ningún conjunto de entrenamiento, esto se alcanza cuando
no se mejora la precisión pese a la adición de nuevas instancias
pseudoetiquetadas.

\begin{algorithm}
    \DontPrintSemicolon
    \KwIn{Conjunto de datos etiquetados $\pmb{L}$, 
    no etiquetados $\pmb{U}$ y algoritmos de aprendizaje $\pmb{A}_1$,..., $\pmb{A}_n$
    }
    \For{i = 1,...,n}{
        $L_i = L$\;
        $e_i = 0$\;
     }
     \Repeat{$L_1$,..., $L_n$ no cambien}{
        \For{i = 1,...,n}{
            Calcular $\pmb{H}_i$ entrenando $\pmb{A}_i$ con $\pmb{L}_i$\;
        }

        \For{cada instancia no etiquetada $x \in U$}{
            \For{cada posible etiqueta j = 1,...,n}{
                $c_j = |\{H_i|H_i(x) = j\}|$
            }
            $k = arg~max_j\{c_j\}$
        }
        /* Instancias propuestas para etiquetar*/\;
        \For{i = 1,...,n}{
            Utilizar $\pmb{L}$ para calcular el intervalo de confianza al 95\%, [$l_i$,~$h_i$] de $\pmb{H}_i$\;
            $w_i = (l_i + h_i)/2$
        }

        \For{i = 1,...,n}{
            $L'_i = \emptyset$\;
        }

        \If{$\sum_{H_j (x)=c_k} w\textsubscript{j} > max_{c'_k \neq c_k} \sum_{H_j (x)=c'_k w_j}$}{
            $L'_i = L'_i  ~\cup~ \{(x,c_k)\}, ~\forall i$ tal que $H_i(x) \neq c_k$
        }

        /* Estimar si añadir $L'_i$ a $L_i$ mejora la exactitud*/\;

        \For{i = 1,...,n}{
            Utilizar $\pmb{L}$ para calcular el intervalo de confianza al 95\%, [$l_i$,~$h_i$] de $\pmb{H}_i$\;
            $q_i = |L_i|(1-2(\frac{e_i}{|L_i|})^2)$   /*Tasa de error*/\;
            $e'_i=(1-\frac{\sum_{i=1}^{d}l_i}{d})|L'_i|$  /*Nueva tasa de error*/\;
            $q'_i = |L_i ~\cup~ L'_i|(1-\frac{2(e_i~+~e'_i)}{|L_i ~\cup~ L'_i|})^2$\;

            \If{$q'_i > q_i$}{
                $L_i = L_i ~\cup~ L'_i$\;
                $e_i = e_i~+~e'_i$\;
            }
        }
        
     }
     \Return{Combinar($\pmb{H}_1,\pmb{H}_2,...,\pmb{H}_n$)}
     \caption{Democratic Co-Learning - entrenamiento}\label{pseudo:democraticco-learning}
\end{algorithm}

\begin{algorithm}
    \DontPrintSemicolon
    \KwIn{$\pmb{H}_1,\pmb{H}_2,...,\pmb{H}_n$ y $x$ (instancia)}
    \KwOut{Hipótesis combinadas (predicción)}
    \For{i = 1,...,n}{
        Utilizar $\pmb{L}$ para calcular el intervalo de confianza al 95\%, [$l_i$,~$h_i$] de $\pmb{H}_i$\;
            $w_i = (l_i + h_i)/2$\;
    }
    \For{i = 1,...,n}{
        \If{$H_i(x)$ predice $c_j$ y $w_i >$ 0.5}{
            Añadir $H_i$ al grupo $G_j$ /* j es etiqueta */\;
        }
    }
    
    \For{j = 1,...,r}{
        $\bar{C}_{G_j} = \frac{|G_j|+0.5}{|G_j|+1} * \frac{\sum_{H_i \in G_j} w_i}{|G_j|}$
    }
    H predice con el grupo $G_k$ con $k = arg~max_j(\bar{C}_{G_j})$\;
    \textbf{return} H
    \caption{Democratic Co-Learning - predicción (combinación)}\label{pseudo:combinar}
\end{algorithm}

Aclaración sobre la predicción final (en combinación): una vez calculadas las
confianzas de la instancia a predecir (x) y por cada posible etiqueta, la idea
de la combinación es obtener la etiqueta (k, posición en el grupo) con mayor
confianza.

\clearpage
\clearpage

\subsection{HTTP (Descripción general)}

Al ser una aplicación Web, este proyecto tiene alta relación con este protocolo.
En el resto del apartado se van a documentar los conceptos que se han utilizado
en el desarrollo.

\textbf{Hypertext Transfer Protocol (HTTP)} o Protocolo de Transferencia de
Hipertexto es un protocolo de la capa de aplicación \footnote{Permite a las
aplicaciones trabajar con los servicios de las capas inferiores y define
protocolos para el intercambio de datos \cite{eswiki:149372346}} para transmitir
documentos. Se trata de un modelo cliente-servidor clásico, el cliente realiza
una petición al servidor, y espera a que este le devuelva una respuesta
\cite{http:mdn}.

\imagen{HTTP}{Diagrama cliente-servidor.}{0.8}


Características de HTTP \cite{http:features}:
\begin{itemize}
	\item Protocolo sin conexión: esto significa que la comunicación antes
	comentada ocurre sin realizar un acuerdo previo entre el cliente y el
	servidor.
	\item Independiente al tipo de contenido: quiere decir que HTTP no limita
	los datos que se pueden enviar, siempre y cuando, tanto el cliente como el
	servidor sepan manejar esos datos.
	\item Protocolo sin estado: cliente y servidor solo saben de su existencia
	durante la comunicación, no retienen la información de peticiones
	anteriores.
\end{itemize}


\subsubsection{Estructura de las peticiones y respuestas}

La realidad es que, peticiones y respuestas, tienen una estructura muy similar. Para las peticiones:
\begin{itemize}
	\item \textbf{Línea de inicio}, formada por:
  \subitem El método HTTP (se describirán a continuación), indica la operación a realizar.
  \subitem El objetivo, generalmente una URL. Para algunos métodos, aquí ser incorporan los parámetros de la petición (<<?param=X>>).
  \subitem Versión del protocolo.
	\item \textbf{Cabeceras}: Son <<metadatos>> que proporcionan información sobre la
  metición. Cada una de ellas (puede haber varias) es un par nombre-valor.	Por
  ejemplo, especificar el tipo de contenido de la petición se haría con
  <<\texttt{Content-Type: application/json}>>.
  \item \textbf{Cuerpo}: Contiene información adicional para el servidor, pudiendo enviar
  cualquier dato. No todas las peticiones llevan cuerpo, una petición GET no lo
  necesita pero sí un POST.
\end{itemize}

Para las respuestas:
\begin{itemize}
	\item \textbf{Línea de estado}, formada por:
  \subitem Versión del protocolo.
  \subitem Código de estado que indican el estado de la petición (se describirán a continuación).
  \subitem Descripción textual del código de estado (para poder interpretarlo).
	\item \textbf{Cabeceras}: Del mismo modo que las peticiones, son <<metadatos>> que
  proporcionan información sobre la petición. Cada una de ellas (puede haber
  varias) es un par nombre-valor.
  \item \textbf{Cuerpo}: Para aquellas respuestas pertinentes (algunas no tienen cuerpo),
  contiene los datos solicitados o generados por el servidor.
\end{itemize}

\imagen{curl}{Ejemplo de respuesta con su estructura.}{0.85}

Como se ha visto en las operaciones HTTP, todas tienen un indicativo, llamado
método, que permite distinguir qué tipo de operación se quiere realizar. El
protocolo HTTP soporta una enorme cantidad de métodos, algunos de ellos son para
contextos muy específicos. Los más utilizados (constantemente en entornos
reales) son \cite{enwiki:1151700575}:
\begin{itemize}
	\item \textbf{GET}: Solicitud de un recurso. Solo para recuperar datos, sin
  otras operaciones. Generalmente a la URL se le añaden parámetros que
  configuran esta solicitud para que el servidor pueda personalizar las
  respuestas.
  \item \textbf{POST}: Solicitud que envía datos en el cuerpo de la petición (es
  el método de los formularios HTML, por ejemplo). Tiene diversas funciones como
  crear un recurso o actualizarlo. Sin embargo, pese a que no está pensado para
  ello, en muchas ocasiones, también se utiliza para solicitar información.
  Entre otras cosas, permite reducir la longitud de las URLs para operaciones
  GET demasiado extensas (incluso que puedan sobrepasar el límite de caracteres)
  y también porque permite ocultar información comprometida
  \cite{http:postnotget}. Las peticiones GET son parametrizadas mediante la
  propia URL, mientras que en POST, los parámetros pueden incorporarse al cuerpo
  de la petición, ocultándolos (interesante por ejemplo, si no se quiere
  compartir identificadores).
  \item \textbf{PUT}: Método similar a POST, también envía datos al servidor,
  pero en este caso está orientado específicamente a la actualización de los
  recursos.
  \item \textbf{DELETE}: Método para eliminar recursos.
\end{itemize}

Los códigos de estado antes mencionados son parte de la respuesta del servidor a
los clientes, indicarán, por lo general, el éxito o fracaso de las operaciones.
Hay aproximadamente 60 códigos distintos, cada uno brinda la posibilidad de
personalizar las respuestas dependiendo del contexto. Todos estos códigos pueden
ir acompañados de la estructura antes comentada. Por ejemplo, para una petición
exitosa, la respuesta de un POST podría tener un \texttt{cuerpo} con más
información. Los códigos más utilizados son:

\begin{itemize}
	\item \textbf{200}: OK, respuesta a peticiones HTTP exitosas.
  \item \textbf{400}: Bad Request, el servidor no puede procesar la petición
  debido a una petición mal construida.
  \item \textbf{401}: Unauthorized, no se tiene las credenciales de
  autenticación válidas para acceder al recurso solicitado.
  \item \textbf{403}: Forbidden, el servidor entiende la petición pero la
  rechaza.
  \item \textbf{404}: Not Found, el recurso no puedo ser encontrado.
  \item \textbf{405}: Method Not Allowed, el método no es soportado para acceder
  al recurso. Por ejemplo, utilizar un GET cuando está pensado para utilizarse
  un POST.
  \item \textbf{PUT}: Internal Server Error, respuesta genérica para errores
  internos, sin mensaje específico de los mismos.
\end{itemize}

\paragraph{HTTP Cookies}

El concepto de las \textit{Cookies} es muy sencillo, son pequeños bloques de
datos que el servidor manda al navegador del usuario mientras accede a él en las
peticiones HTTP. Una vez que el cliente ha almacenado esta información, puede
usarla para agilizar ciertos pasos en las siguientes peticiones. Cuando vuelva a
acceder, junto con la petición <<normal>> enviará esta porción de datos, que el
servidor puede interpretar y reconocer. Por ejemplo, pueden guardarse los
inicios de sesión, preferencias o en entornos comerciales, el comportamiento del
usuario.

La idea interesante de las \textit{Cookies} es que permite almacenar
\textbf{información de estado} para el protocolo HTTP, que es \textbf{sin
estado} (por sí solo no puede guardar esta información).


\section{CSRF (Cross-Site Request Forgery)}

Cross-Site Request Forgery (Falsificación de petición en sitios cruzados) es un
ataque sobre aplicaciones Web vulnerables en las que se utiliza a un usuario
autenticado en la misma (o en el que la Web confía) para enviar una petición
maliciosa. Los ataques CSRF explotan la confianza que una Web tiene con un
usuario, al no poder diferencia entre una petición generada por el usuario (la
persona) y la petición generada por el usuario, pero sin su consentimiento
\cite{csrf} (generalmente de forma cruzada, proveniente de otro contexto).

Se presenta un ejemplo explicativo:

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=Situación]
Web vulnerable: \url{https://ejemplo.es}

Usuario: David (con sesión iniciada)

URL de cambio de contraseña: \url{https://ejemplo.es/cambiarcontrasena} 
(permite un parámetro <<nueva>> mediante POST para especificar la nueva contraseña)

El servidor a <<securizado>> parcialmente la URL anterior comprobando que el que
accede a esa URL es el propio usuario con sesión iniciada.
\end{tcolorbox}


\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Atacante]
    \begin{enumerate}
        \item Ha hecho ingeniería social para saber el Email de David: david@ejemplo.es.
        \item Envía un correo electrónico con un enlace que parece de Google.
        \item En realidad, todos los botones de esa página envían un formulario (POST)
        hacia \url{https://ejemplo.es/cambiarcontrasena}.
        \item El formulario tiene un campo oculto:
        \mint{html}|<input type="hidden" name="nueva" value="hackeado"/>|
    \end{enumerate}
\end{tcolorbox}

\begin{tcolorbox}[colback=green!5!white,colframe=green!75!black,title=David]
    \begin{enumerate}
        \item Recibe el correo en su bandeja de entrada.
        \item No se percata de que no es la página original de Google y entra en ella.
        \item Busca información en Google y pincha en un botón.
        \item Se realiza la petición POST a la Web vulnerable en la que ha iniciado sesión.
        \item El servidor procesa la petición pues cree que es el propio usuario el que ha
        construido la petición conscientemente.
        \item La contraseña ha cambiado a <<hackeado>>.
    \end{enumerate}
\end{tcolorbox}

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Atacante]

Con el Email <<david@ejemplo.es>> y la contraseña <<hackeado>>, accede a la Web
<<ejemplo.es>> como si fuera David.

\end{tcolorbox}

\paragraph{Solución} Dada la vulnerabilidad comentada anteriormente, la solución pasa por idear una
forma de saber que esa petición se ha creado desde la propia aplicación (no por
terceros). Por lo tanto, la idea más efectiva es la creación de un <<CSRF
token>> único para los usuarios, que el servidor (aplicación) genera y
<<guarda>> en la sesión de los mismos. Este <<token>> es incrustado como un
parámetro oculto en las peticiones (en los formularios) y al realizar el envío
del formulario, el servidor comprobará que el <<token>> recibido era el correcto
para el usuario.

