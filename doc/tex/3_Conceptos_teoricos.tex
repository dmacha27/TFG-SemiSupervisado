\capitulo{3}{Conceptos teóricos}


\section{Aprendizaje automático}

Según \cite{intelligent:ml}, el aprendizaje automático (\textit{machine
learning}) es una rama de la Inteligencia artificial como una técnica de
análisis de datos que enseña a las computadoras a aprender de la
\textbf{experiencia} (es decir, lo que realizan los humanos). Para ello, el
aprendizaje automático se nutre de gran cantidad de datos (o los suficientes
para el problema concreto) que son procesados por ciertos algoritmos. Estos
datos son ejemplos (también llamados instancias o prototipos), \cite{pascual:ml}
mediante los cuales, los algoritmos son capaces de generalizar comportamientos
que se encuentran ocultos. 

La característica principal de estos algoritmos es que son capaces de mejorar su
rendimiento de forma automática basándose en procesos de entrenamiento y también
en las fases posteriores de explotación. Debido a sus propiedades, el
aprendizaje automático se ha convertido en un campo de alta importancia,
aplicándose a multitud de campos como medicina, automoción, visión
artificial\ldots Los tipos de aprendizaje automático se suelen clasificar en los
siguientes: aprendizaje supervisado, aprendizaje no supervisado y aprendizaje
por refuerzo. Sin embargo, aparece una nueva disciplina que se encuentra a
caballo entre el supervisado y no supervisado (utiliza tanto datos etiquetados
como no etiquetados para el entrenamiento) \cite{vanEngelen2020}.

En la figura \ref{fig:taxonomia} se puede ver una
clasificación de aprendizaje automático.

\imagen{taxonomia}{Clasificación de aprendizaje automático \cite{neova:taxonomy}.}{1}


\subsection{Aprendizaje supervisado}

El aprendizaje supervisado es una de las aproximaciones del aprendizaje
automático. Los algoritmos de aprendizaje supervisado son entrenados con datos
que han sido etiquetados para una salida concreta \cite{david:sl}. Por ejemplo,
dadas unas biopsias de pacientes, una posible etiqueta es si padecen de cáncer o
no. Estos datos tienen una serie de características (e.g. en el caso de una
biopsia se tendría la edad, tamaño tumoral, si ha tenido lugar mitosis o no...)
y todas ellas pueden ser binarias, categóricas o continuas \cite{salim:sl}.

Es común que antes del entrenamiento, estos datos son particionados en: conjunto de
entrenamiento, conjunto de test o conjunto de validación. De forma resumida, el
conjunto de entrenamiento serán los datos que utilice el propio algoritmo para
aprender y generalizar los comportamientos ocultos de los mismos. El conjunto de
validación se utilizará para tener un control de que el modelo está
generalizando y no sobreajustando (memorizando los datos) y por último, el
conjunto de test sirve para estimar el rendimiento real que podrá tener el
modelo en explotación \cite{enwiki:conjuntos}. En la figura
\ref{fig:aprendizajesupervisado} puede visualizarse el funcionamiento general.

\imagen{aprendizajesupervisado}{Funcionamiento general del aprendizaje supervisado \cite{salim:sl}.}{1}

El aprendizaje supervisado está altamente influenciado por esto. Por un lado, si
las etiquetas son categóricas o binarias el modelo será de
\textbf{clasificación} y por otro, si las etiquetas son continuas el modelo será
de \textbf{regresión}.

\begin{itemize}
    \item \textbf{Clasificación}: Los algoritmos de clasificación, a veces
    denominados simplemente como clasificadores, tratan de predecir la clase de
    una nueva entrada a partir del entrenamiento previo realizado. Estas clases
    son discretas y en clasificación pueden referirse a clases (o etiquetas)
    binarias o clases múltiples.
    
    \item \textbf{Regresión}: En este caso, el algoritmo asigna un valor
    continuo a una entrada. Es decir, trata de encontrar una función continua
    basándose en las variables de entrada. Se denomina también ajuste de
    funciones.
\end{itemize}

\clearpage

\subsection{Aprendizaje no supervisado}

A diferencia del aprendizaje supervisado, en el no supervisado, los algoritmos
no se nutren de datos etiquetados. En otras palabras, los usuarios no "<supervisan"> el modelo
\cite{salim:usl}. Esto quiere decir que no aprenderán de etiquetas, sino de la
propia estructura que se encuentre en los datos (patrones). Por ejemplo, dadas
unas imágenes de animales, sin especificar cuál es cuál, el aprendizaje no
supervisado identificará las similitudes entre imágenes y como resultado podría
dar la separación de las especies (o separaciones entre colores, pelaje,
raza...).

Como principales usos del aprendizaje no supervisado, suele aplicarse a:
\vspace{-4px}
\begin{enumerate}
    \item \textbf{Agrupamiento (Clustering)}: Este modelo de aprendizaje no
    supervisado trata de dividir los datos en grupos. Para ello, estudia las
    similitudes entre ellos y también en las disimilitudes con otros. Estos
    modelos pueden tanto descubrir por ellos mismos los "<clústeres"> o grupos
    que se encuentran o indicarle cuántos debe identificar \cite{salim:usl}.
    \item \textbf{Reducción de la dimensionalidad}: Para empezar, el término
    "<dimensionalidad"> hace referencia al número de variables de entrada que
    tienen los datos. En la realidad, los conjuntos de datos sobre los que se
    trabaja suelen tener una dimensionalidad grande. Según
    \cite{javatpoint:reduccionsdims} la reducción de dimensionalidad se denomina
    como "<Una forma de convertir conjuntos de datos de alta dimensionalidad en
    conjunto de datos de menor dimensionalidad, pero garantizando que proporciona
    información similar">. Es decir, simplificar el problema pero sin perder
    toda esa estructura interesante de los datos. Algunos ejemplos pueden ser:
    \begin{itemize}
        \item Análisis de Componentes Principales (PCA)
        \item Cuantificación vectorial
        \item Autoencoders
    \end{itemize}
\end{enumerate}

\imagenconurl{clustering}{Clusters}{\footnotesize{Clusters - By hellisp - Own
work, Public Domain,
\url{https://commons.wikimedia.org/w/index.php?curid=36929773}. Ejemplo de
clustering, a la izquierda los datos no etiquetados y a la derecha los datos
coloreados según las clases identificadas por el algoritmo de clustering.
}}{0.5} 
\subsection{Aprendizaje semi-supervisado}

Según \cite{vanEngelen2020} el aprendizaje semi-supervisado es la rama del
aprendizaje automático referido al uso de datos tanto etiquetados como no
etiquetados simultáneamente para realizar tareas de aprendizaje. Se encuentra a
caballo  entre el aprendizaje supervisado y no supervisado. Concretamente, los
problemas donde más se aplica, y donde más investigación se realiza es en
clasificación. Los métodos semi-supervisados resultan especialmente útiles
cuando se tienen escasos datos etiquetados, que, aparte de ser una situación
común en problemas reales, el proceso de etiquetado es una labor compleja, que
consume tiempo y es costosa.

\subsubsection{Suposiciones}
El objetivo de usar datos no etiquetados es construir un clasificador que sea
mejor que el aprendizaje supervisado, en el que solo se tienen datos
etiquetados. Pero para que el aprendizaje semi-supervisado mejore a lo ya
existente, tiene una serie de suposiciones que han de cumplirse.

En primera instancia se dice que la condición necesaria es que la distribución
\textit{p(x)} del espacio de entrada contiene información sobre la distribución
posterior \textit{p(y|x)} \cite{vanEngelen2020}.

Pero la forma en el que interactúan los datos de una distribución y la posterior,
no siempre es la misma:

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Smoothness assumption}]
    Esta suposición indica que si dos ejemplos (o instancias) de la entrada
    están cerca en ese espacio de entrada, entonces, probablemente, sus
    etiquetas sean las mismas.
\end{tcolorbox}

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Low-density assumption}]
    Esta suposición indica que en clasificación, los límites de decisión deben
    encontrarse en zonas en las que haya pocos de estos ejemplos (o instancias).
\end{tcolorbox}

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Manifold assumption}]
    Los datos pueden tener una dimensionalidad alta (muchas características)
    pero generalmente no todas las características son completamente útiles. Los
    datos a menudo se encuentran en unas estructuras de más baja
    dimensionalidad. Estas estructuras se conocen como "<manifolds">. Esta
    suposición indica que si los datos del espacio de entrada se encuentran en
    estas "<manifolds"> entonces aquellos puntos que se encuentren en el mismo
    "<manifolds"> tendrán la misma etiqueta. \cite{towardsdatascience:semi,vanEngelen2020}
\end{tcolorbox}

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Cluster assumption}]
    Como generalización de las anteriores, aquellos datos que se encuentren en
    un mismo clúster tendrán la misma etiqueta.
\end{tcolorbox}


De estas suposiciones se extrae el concepto de "<similitud"> en el que en todas
ellas se encuentra presente. Y en realidad, todas son versiones de
\textit{Cluster assumption} en la que los puntos similares tienden a pertenecer
al mismo grupo. 

Además, la suposición de clúster resulta necesaria para que el aprendizaje
semi-supervisado mejore al supervisado. Si los datos no pueden ser agrupados,
entonces no mejorará ningún método supervisado~\cite{vanEngelen2020}.


Para tener un punto de vista general, en la figura \ref{fig:aprendizajesemisupervisado} se presenta la
taxonomía de los métodos de aprendizaje semi-supervisado.

\imagen{aprendizajesemisupervisado}{Métodos semi-supervisados \cite{vanEngelen2020}.}{1}

El núcleo de este proyecto está basado en los métodos inductivos. Su idea es muy
sencilla y está altamente relacionada con el objetivo del aprendizaje
supervisado, trata de crear un clasificador que prediga etiquetas para datos
nuevos. Por lo tanto, los algoritmos construidos tendrán este objetivo, aunque
con un punto más de concreción: los métodos "<wrapper"> o de envoltura.

Los conocidos métodos "<wrapper"> se basan en el \texttt{pseudo etiquetado}
("<pseudo-labelling">), es el proceso en el que los clasificadores entrenados
con datos etiquetados generan etiquetas para los no etiquetados. Una vez
completado este proceso, el clasificador se vuelve a entrenar pero añadiendo
estos nuevos datos.

La gran ventaja que suponen estos métodos es que pueden utilizarse con casi
todos los clasificadores (supervisados) existentes \cite{vanEngelen2020}.

\paragraph{Self-Training}
Se trata del método de aprendizaje semi-supervisado más sencillo y "<directo">.
Este método envuelve un único clasificador base, que entrena con los datos
etiquetados iniciales y aprovecha el proceso de pseudo etiquetado comentado para
continuar su entrenamiento.

El método comienza por entrenar ese clasificador con los datos etiquetados que
se tienen. A partir de este aprendizaje, se etiqueta el resto de datos. De todas
las nuevas predicciones se seleccionan aquellas que parecen haber acertado con
mayor probabilidad. Una vez seleccionados, el clasificador es reentrenado con la
unión los ya etiquetados y estos nuevos. El proceso continúa hasta un criterio
de parada (generalmente hasta etiquetar todos los datos o un número máximo de
iteraciones).

En este proceso, el paso más importante es la incorporación de nuevos datos al
de conjunto de etiquetados, porque, \textbf{probablemente}, la predicción sea la
correcta. Es importante entonces que el cálculo de la probabilidad se realice
correctamente para asegurar que los nuevos datos son de interés. En caso
contrario, no es posible aprovechar los beneficios que ofrece self-training
\cite{vanEngelen2020}. Todo este proceso queda descrito en
\ref{pseudo:self-training}.

\begin{algorithm}
    \KwIn{Conjunto de datos etiquetados \textbf{\textit{L}}, 
    no etiquetados \textbf{\textit{U}} y clasificador \textbf{\textit{H}}}
    \KwOut{Clasificador}
     \While{$|U| \neq 0$}{
        Entrenar \textbf{\textit{H}} con \textbf{\textit{L}}\;
        Predecir etiquetas de \textbf{\textit{U}}\;
        Seleccionar un conjunto \textbf{\textit{T}} con aquellos datos que tenga la mayor probabilidad\;
        $\textbf{\textit{L}} = \textbf{\textit{L}} \cup \textbf{\textit{T}}$\;
        $\textbf{\textit{U}} = \textbf{\textit{U}} - \textbf{\textit{T}}$\;
     }
     Entrenar \textbf{\textit{H}} con \textbf{\textit{L}}\;
     \textbf{return} \textbf{\textit{H}}
     \caption{Self-Training}\label{pseudo:self-training}
\end{algorithm}

Sobre esta base, el algoritmo tiene muchas formas de diseñarse. En algunos casos
la condición de parada suele tomarse como un número de máximo de iteraciones.
También, la cantidad de datos que se incorporan al conjunto \textbf{L} (con
mayor confianza) puede ser fija, o mediante un límite mínimo de
confianza/probabilidad (todas las instancias con mayor probabilidad se añaden).

\paragraph{Co-Training}
Basado fuertemente en Self-Training, en este caso \textbf{varios} clasificadores
(normalmente dos) se encargan del proceso e <<interactúan>> entre sí. Del mismo
modo, una vez entrenados predicen las etiquetas de los no clasificados y todos
los clasificadores añaden las mejores predicciones (mayor
confianza/probabilidad).

En \cite{blum1998combining}, Blum y Mitchel propusieron el funcionamiento básico
de Co-Training con dos vistas sobre los datos (<<multi-view>>). Estas vistas
corresponden no con subconjuntos de las instancias sino de subconjuntos de las
características de las mismas. Es decir, cada clasificador va a entrenarse
teniendo en cuenta características distintas. Idealmente estas vistas son
independientes y pueden predecir por sí solas la etiqueta (aunque no siempre se
cumplirá). Cuando los clasificadores predicen etiquetas sobre los datos se
seleccionan de ambos los de mayor confianza y construyen el nuevo conjunto de
entrenamiento para la siguiente iteración.


\begin{algorithm}
    \KwIn{Conjunto de datos etiquetados \textbf{\textit{L}}, 
    no etiquetados \textbf{\textit{U}}, clasificadores \textbf{\textit{H\textsubscript{1}}}
    y \textbf{\textit{H\textsubscript{2}}}, \textit{p} (positivos), 
    \textit{n} (negativos), \textit{u} (datos iniciales), \textit{k} (iteraciones)}
    \KwOut{Clasificadores entrenados}
    Crear subconjunto \textbf{\textit{U'}} seleccionando \textit{u} instancias aleatorias de \textbf{\textit{U}}\;
    \For{k iteraciones}{
        Entrenar \textbf{\textit{H\textsubscript{1}}} con \textbf{\textit{L}}
        solo considerando un subconjunto (\textit{x\textsubscript{1}}) de las características de cada instancia (\textit{x})\;
        Entrenar \textbf{\textit{H\textsubscript{2}}} con \textbf{\textit{L}}
        solo considerando el otro subconjunto (\textit{x\textsubscript{2}}) de las características de cada instancia (\textit{x})\;

        Hacer que \textbf{\textit{H\textsubscript{1}}} prediga \textit{p} instancias positivas y \textit{n} negativas de \textbf{\textit{U'}} que tengan la mejor confianza\;
        Hacer que \textbf{\textit{H\textsubscript{2}}} prediga \textit{p} instancias positivas y \textit{n} negativas de \textbf{\textit{U'}} que tengan la mejor confianza\;
        Añadir estas instancias seleccionadas a \textbf{\textit{L}}\;
        Reponer \textbf{\textit{U'}} añadiendo 2p + 2n instancias de \textbf{\textit{U}}\;
     }
     \textbf{return} \textbf{\textit{H\textsubscript{1}}},\textbf{\textit{H\textsubscript{2}}}
     \caption{Co-Training}\label{pseudo:co-training}
\end{algorithm}


