\capitulo{3}{Conceptos teóricos}

En esta sección se presentarán los principales conceptos teóricos del proyecto.
Estos incluyen el aprendizaje automático y más específicamente el aprendizaje
semi-supervisado.

\section{Aprendizaje automático}

Según~\cite{intelligent:ml}, el aprendizaje automático (\textit{machine
learning}) es una rama de la Inteligencia Artificial como una técnica de
análisis de datos que enseña a las computadoras a aprender de la
\textbf{experiencia} (es decir, lo que realizan los humanos). Para ello, el
aprendizaje automático se nutre de gran cantidad de datos (o los suficientes
para el problema concreto) que son procesados por ciertos algoritmos. Estos
datos son ejemplos (también llamados instancias o prototipos),~\cite{pascual:ml}
mediante los cuales, los algoritmos son capaces de generalizar comportamientos
que se encuentran ocultos. 

La característica principal de estos algoritmos es que son capaces de mejorar su
rendimiento de forma automática basándose en procesos de entrenamiento y también
en las fases posteriores de explotación. Debido a sus propiedades, el
aprendizaje automático se ha convertido en un campo de alta importancia,
aplicándose a multitud de campos como medicina, automoción, visión
artificial... Los tipos de aprendizaje automático se suelen clasificar en los
siguientes: aprendizaje supervisado, aprendizaje no supervisado y aprendizaje
por refuerzo. Sin embargo, aparece una nueva disciplina que se encuentra a
caballo entre el supervisado y no supervisado (utiliza tanto datos etiquetados
como no etiquetados para el entrenamiento)~\cite{vanEngelen2020}.

En la figura~\ref{fig:memoria/taxonomia} se puede ver una
clasificación de aprendizaje automático.

\imagen{memoria/taxonomia}{Clasificación de aprendizaje automático~\cite{neova:taxonomy}.}{1}


\subsection{Aprendizaje supervisado}

El aprendizaje supervisado es una de las aproximaciones del aprendizaje
automático. Los algoritmos de aprendizaje supervisado son entrenados con datos
que han sido etiquetados para una salida concreta~\cite{david:sl}. Por ejemplo,
dadas unas biopsias de pacientes, una posible etiqueta es si padecen de cáncer o
no. Estos datos tienen una serie de características (e.g. en el caso de una
biopsia se tendría la edad, tamaño tumoral, si ha tenido lugar mitosis o no...)
y todas ellas pueden ser binarias, categóricas o continuas~\cite{salim:sl}.

Es común que antes del entrenamiento, estos datos sean particionados en:
conjunto de entrenamiento, conjunto de test y conjunto de validación. De forma
resumida, el conjunto de entrenamiento serán los datos que utilice el propio
algoritmo para aprender y generalizar los comportamientos ocultos de los mismos.
El conjunto de validación se utilizará para tener un control de que el modelo
está generalizando y no sobreajustando (memorizando los datos) y también para
decidir cuando finalizar el entrenamiento. Por último, el conjunto de test sirve
para estimar el rendimiento real que podrá tener el modelo en explotación
~\cite{enwiki:conjuntos}. En la figura~\ref{fig:memoria/aprendizajesupervisado}
puede visualizarse el funcionamiento general.

\imagen{memoria/aprendizajesupervisado}{Funcionamiento general del aprendizaje supervisado~\cite{salim:sl}.}{1}

El aprendizaje supervisado está altamente influenciado por esto. Por un lado, si
el valor a predecir es uno entre un conjunto finito, el modelo será de
\textbf{clasificación} y por otro, si el valor a predecir es un valor continuo,
el modelo será de \textbf{regresión}.

\begin{itemize}
    \item \textbf{Clasificación}: Los modelos de clasificación (generados a
    partir de algoritmos de aprendizaje), a veces denominados simplemente como
    clasificadores, tratan de predecir la clase de una nueva entrada a partir
    del entrenamiento previo realizado. Estas clases son discretas y en
    clasificación pueden referirse a clases (o etiquetas) binarias o clases
    múltiples.
    
    \item \textbf{Regresión}: En este caso, el modelo asigna un valor continuo a
    una entrada. Es decir, trata de encontrar una función continua basándose en
    las variables de entrada. Se denomina también ajuste de funciones.
\end{itemize}

\clearpage

\subsection{Aprendizaje no supervisado}

A diferencia del aprendizaje supervisado, en el no supervisado, los algoritmos
de aprendizaje no se nutren de datos etiquetados. En otras palabras, los
usuarios no "<supervisan"> el algoritmo~\cite{salim:usl}. Esto quiere decir que
no aprenderán de etiquetas, sino de la propia estructura que se encuentre en los
datos (patrones). Por ejemplo, dadas unas imágenes de animales, sin especificar
cuál es cuál, el aprendizaje no supervisado identificará las similitudes entre
imágenes y como resultado podría dar la separación de las especies (o
separaciones entre colores, pelaje, raza...).

Como principales usos del aprendizaje no supervisado, suele aplicarse a:
\vspace{-4px}
\begin{enumerate}
    \item \textbf{Agrupamiento (Clustering)}: Este tipo de algoritmo de
    aprendizaje no supervisado trata de dividir los datos en grupos. Para ello,
    estudia las similitudes entre ellos y también en las disimilitudes con
    otros. Estos algoritmos pueden tanto descubrir por ellos mismos los
    <<clústeres>> o grupos que se encuentran o indicarle cuántos debe
    identificar~\cite{salim:usl}.
    \item \textbf{Reducción de la dimensionalidad}: Para empezar, el término
    "<dimensionalidad"> hace referencia al número de variables de entrada que
    tienen los datos. En la realidad, los conjuntos de datos sobre los que se
    trabaja suelen tener una dimensionalidad grande. Según
   ~\cite{javatpoint:reduccionsdims} la reducción de dimensionalidad se denomina
    como: \begin{quote}<<\textit{Una forma de convertir conjuntos de datos de alta dimensionalidad en
    conjunto de datos de menor dimensionalidad, pero garantizando que proporciona
    información similar.}>>\end{quote} Es decir, simplificar el problema pero sin perder
    toda esa estructura interesante de los datos. Algunos ejemplos pueden ser:
    \begin{itemize}
        \item Análisis de Componentes Principales (PCA).
        \item Cuantificación vectorial.
        \item Autoencoders.
    \end{itemize}
\end{enumerate}

\imagenconurl{memoria/clustering}{Clusters}{\footnotesize{\emph{Clusters}. Ejemplo de
agrupamiento, a la izquierda los datos no etiquetados y a la derecha los datos
coloreados según las clases identificadas por el algoritmo de clustering. By
hellisp - Own work, Public Domain,
\url{https://commons.wikimedia.org/w/index.php?curid=36929773}. }}{0.5} 
\subsection{Aprendizaje semi-supervisado}

Según~\cite{vanEngelen2020}, el aprendizaje semi-supervisado es la rama del
aprendizaje automático referido al uso simultáneo de datos tanto etiquetados
como no etiquetados para realizar tareas de aprendizaje. Se encuentra a caballo
entre el aprendizaje supervisado y el no supervisado. Concretamente, los
problemas donde más se aplica, y donde más investigación se realiza es en
clasificación. Los métodos semi-supervisados resultan especialmente útiles
cuando se tienen escasos datos etiquetados, que, aparte de ser una situación
común en problemas reales, hacen que el proceso de etiquetado sea una labor
compleja, que consume tiempo y es costosa.

\subsubsection{Suposiciones}
El objetivo de usar datos no etiquetados es construir un clasificador que sea
mejor que el que se obtendría utilizando aprendizaje supervisado, donde solo se
tienen datos etiquetados. Pero para que el aprendizaje semi-supervisado mejore a
lo ya existente, tiene una serie de suposiciones que han de cumplirse.

En primera instancia se dice que la condición necesaria es que la distribución
$p(x)$ del espacio de entrada contiene información sobre la distribución
posterior $p(y|x)$~\cite{vanEngelen2020}.

Pero la forma en el que interactúan los datos de una distribución y la posterior,
no siempre es la misma:

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Smoothness assumption}]
    Esta suposición indica que si dos ejemplos (o instancias) de la entrada
    están cerca en ese espacio de entrada, entonces, probablemente, sus
    etiquetas sean las mismas.
\end{tcolorbox}

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Low-density assumption}]
    Esta suposición indica que en clasificación, los límites de decisión deben
    encontrarse en zonas en las que haya pocos de estos ejemplos (o instancias).
\end{tcolorbox}

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Manifold assumption}]
    Los datos pueden tener una dimensionalidad alta (muchas características)
    pero generalmente no todas las características son completamente útiles. Los
    datos a menudo se encuentran en unas estructuras de más baja
    dimensionalidad. Estas estructuras se conocen como \emph{manifolds}.
    Esta suposición indica que si los datos del espacio de entrada se encuentran
    en estas \emph{manifolds} entonces aquellos puntos que se encuentren en
    el mismo \emph{manifolds} tendrán la misma etiqueta.
   ~\cite{towardsdatascience:semi,vanEngelen2020}
\end{tcolorbox}

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=\textit{Cluster assumption}]
    Como generalización de las anteriores, aquellos datos que se encuentren en
    un mismo clúster tendrán la misma etiqueta.
\end{tcolorbox}


De estas suposiciones se extrae el concepto de "<similitud"> que está presente
en todas ellas. Y en realidad, todas son versiones de la \textit{Cluster
assumption}, que dice que los puntos similares tienden a pertenecer al mismo
grupo. 

Además, la suposición de clúster resulta necesaria para que el aprendizaje
semi-supervisado mejore al supervisado. Si los datos no pueden ser agrupados,
entonces no mejorará ningún método supervisado~\cite{vanEngelen2020}.


Para tener un punto de vista general, en la figura~\ref{fig:memoria/aprendizajesemisupervisado} se presenta la
taxonomía de los métodos de aprendizaje semi-supervisado.

\imagen{memoria/aprendizajesemisupervisado}{Taxonomía de métodos semi-supervisados
~\cite{vanEngelen2020}.}{1}

El núcleo de este proyecto está basado en los métodos inductivos. Su idea es muy
sencilla y está altamente relacionada con el objetivo del aprendizaje
supervisado, trata de crear un clasificador que prediga etiquetas para datos
nuevos. Por lo tanto, los algoritmos construidos tendrán este objetivo, aunque
con un punto más de concreción: el proyecto se centrará en los métodos
\emph{wrapper} o de envoltura.

Los conocidos métodos \emph{wrapper} se basan en el \textit{pseudo etiquetado}
(<<pseudo-labelling>>), es el proceso en el que los clasificadores entrenados
con datos etiquetados generan etiquetas para los no etiquetados. Una vez
completado este proceso, el clasificador se vuelve a entrenar pero añadiendo
estos nuevos datos. La gran ventaja que suponen estos métodos es que pueden
utilizarse con casi todos los clasificadores (supervisados) existentes
~\cite{vanEngelen2020}.

\section{Self-Training}
Se trata del método de aprendizaje semi-supervisado más sencillo y <<directo>>.
Este método <<envuelve>> un único clasificador base, que entrena con los datos
etiquetados iniciales y aprovecha el proceso de pseudo etiquetado comentado para
continuar su entrenamiento.

El método comienza por entrenar ese clasificador con los datos etiquetados que
se tienen. A partir de este aprendizaje inicial, se etiqueta el resto de datos.
De todas las nuevas predicciones se seleccionan aquellas en las que el
clasificador más confianza tiene (de haber acertado). Una vez seleccionados, el
clasificador es reentrenado con la unión de los ya etiquetados y estos recién
etiquetados. El proceso continúa hasta que se verifica un criterio de parada
(generalmente hasta etiquetar todos los datos o un número máximo de
iteraciones).

En este proceso, el paso más importante es la incorporación de nuevos datos al
conjunto de etiquetados porque, \textbf{probablemente}, la predicción sea la
correcta. Es importante entonces que el cálculo de la probabilidad se realice
correctamente para asegurar que los nuevos datos son de interés. En caso
contrario, no es posible aprovechar los beneficios que ofrece self-training~
~\cite{vanEngelen2020}. Todo este proceso queda descrito en el algoritmo
~\ref{pseudo:self-training}.

\begin{algorithm}
    \DontPrintSemicolon
    \KwIn{Conjunto de datos etiquetados \bfit{L}, 
    no etiquetados \bfit{U} y clasificador \bfit{H}}
    \KwOut{Clasificador entrenado}
     \While{$|U| \neq 0$}{
        Entrenar \bfit{H} con \bfit{L}\;
        Predecir etiquetas de \bfit{U}\;
        Seleccionar un conjunto \bfit{T} con aquellos datos que tenga la mayor probabilidad\;
        $\bfit{L} = \bfit{L} \cup \bfit{T}$\;
        $\bfit{U} = \bfit{U} - \bfit{T}$\;
     }
     Entrenar \bfit{H} con \bfit{L}\;
     \textbf{return} \bfit{H}
     \caption{Self-Training}\label{pseudo:self-training}
\end{algorithm}

Sobre esta base, el algoritmo tiene muchas formas de diseñarse. En algunos casos
la condición de parada suele tomarse como un número máximo de iteraciones.
También, la cantidad de datos que se incorporan al conjunto \bfit{L}
(con mayor confianza) puede ser fija, o mediante un límite mínimo de
confianza/probabilidad (todas las instancias con mayor probabilidad se
añadirían).

\section{Co-Training}
Basado fuertemente en Self-Training, en este caso \textbf{varios} clasificadores
(normalmente dos) se encargan del proceso e <<interactúan>> entre sí. Del mismo
modo, una vez entrenados predicen las etiquetas de los no clasificados y todos
los clasificadores añaden las mejores predicciones.

En~\cite{blum1998combining}, Blum y Mitchel propusieron el funcionamiento básico
de Co-Training con dos vistas sobre los datos (\emph{multi-view}). Estas vistas
corresponden no con subconjuntos de las instancias, sino con subconjuntos de las
características de las mismas. Es decir, cada clasificador va a entrenarse
teniendo en cuenta características distintas. Idealmente estas vistas tendrían
que ser independientes y servir por sí solas para predecir la etiqueta (aunque
no siempre se cumplirá). Cuando los clasificadores predicen etiquetas sobre los
datos, se seleccionan de ambos los de mayor confianza y se construye el nuevo
conjunto de entrenamiento para la siguiente iteración.


\begin{algorithm}
    \DontPrintSemicolon
    \KwIn{Conjunto de datos etiquetados $\pmb{L}$, 
    no etiquetados $\pmb{U}$, clasificadores $\pmb{H}_1$
    y $\pmb{H}_2$, $p$ (positivos), 
    $n$ (negativos), $u$ (número de datos iniciales), $k$ (iteraciones)}
    \KwOut{Clasificadores entrenados}
    Crear un subconjunto $\pmb{U'}$ seleccionando $u$ instancias aleatorias de $\pmb{U}$\;
    \For{k iteraciones}{
        Entrenar $\pmb{H}_1$ con $\pmb{L}$
        solo considerando un subconjunto ($\pmb{x}_1$) de las características de cada instancia ($x$)\;
        Entrenar $\pmb{H}_2$ con $\pmb{L}$
        solo considerando el otro subconjunto ($\pmb{x}_2$) de las características de cada instancia ($x$)\;

        Hacer que $\pmb{H}_1$ prediga $p$ instancias positivas y $n$ negativas de $\pmb{U'}$ que tengan la mayor confianza\;
        Hacer que $\pmb{H}_2$ prediga $p$ instancias positivas y $n$ negativas de $\pmb{U'}$ que tengan la mayor confianza\;
        Añadir estas instancias seleccionadas a $\pmb{L}$\;
        Reponer $\pmb{U'}$ añadiendo $2p + 2n$ instancias de $\pmb{U}$\;
     }
     \Return{$\pmb{H}_1,\pmb{H}_2$}
     \caption{Co-Training}\label{pseudo:co-training}
\end{algorithm}

\clearpage
\section{Democratic Co-Learning}

Yan Zhou y Sally Goldman presentaron en~\cite{zhou2004democratic} un algoritmo
de aprendizaje semi-supervisado en la línea del Co-Training (varios
clasificadores). La diferencia sustancial es que los clasificadores base no
trabajan con dos (o más) conjunto de atributos (para que cada clasificador
utilice uno de ellos), en este caso solo se tiene un único conjunto de atributos
(\emph{single-view}).

Partiendo de los datos etiquetados, varios clasificadores realizan votación
ponderada sobre los no etiquetados. Lo que quiere decir que, para una instancia,
su nueva etiqueta será la que vote la mayoría. Además, para aquellos
clasificadores que no votan como la mayoría, la instancia se añade a su conjunto
de entrenamiento junto a la etiqueta mayoritaria, de esta forma se <<obliga>> en
la siguiente iteración a <<aprenderla>>. Todo el proceso se repite hasta que no
se añadan más instancias a ningún conjunto de entrenamiento, esto ocurrirá
cuando no se mejora la precisión pese a la adición de nuevas instancias
pseudo-etiquetadas.

\begin{algorithm}
    \DontPrintSemicolon
    \KwIn{Conjunto de datos etiquetados $\pmb{L}$, 
    no etiquetados $\pmb{U}$ y algoritmos de aprendizaje $\pmb{A}_1$,..., $\pmb{A}_n$
    }
    \For{i = 1,...,n}{
        $L_i = L$\;
        $e_i = 0$\;
     }
     \Repeat{$L_1$,..., $L_n$ no cambien}{
        \For{i = 1,...,n}{
            Calcular $\pmb{H}_i$ entrenando $\pmb{A}_i$ con $\pmb{L}_i$\;
        }

        \For{cada instancia no etiquetada $x \in U$}{
            \For{cada posible etiqueta j = 1,...,n}{
                $c_j = |\{H_i|H_i(x) = j\}|$
            }
            $k = arg~max_j\{c_j\}$
        }
        /* Instancias propuestas para etiquetar */\;
        \For{i = 1,...,n}{
            Utilizar $\pmb{L}$ para calcular el intervalo de confianza al 95\%, [$l_i$,~$h_i$] de $\pmb{H}_i$\;
            $w_i = (l_i + h_i)/2$
        }

        \For{i = 1,...,n}{
            $L'_i = \emptyset$\;
        }

        \If{$\sum_{H_j (x)=c_k} w\textsubscript{j} > max_{c'_k \neq c_k} \sum_{H_j (x)=c'_k w_j}$}{
            $L'_i = L'_i  ~\cup~ \{(x,c_k)\}, ~\forall i$ tal que $H_i(x) \neq c_k$
        }

        /* Estimar si añadir $L'_i$ a $L_i$ mejora la exactitud */\;

        \For{i = 1,...,n}{
            Utilizar $\pmb{L}$ para calcular el intervalo de confianza al 95\%, [$l_i$,~$h_i$] de $\pmb{H}_i$\;
            $q_i = |L_i|(1-2(\frac{e_i}{|L_i|})^2)$   /* Tasa de error */\;
            $e'_i=(1-\frac{\sum_{i=1}^{d}l_i}{d})|L'_i|$  /* Nueva tasa de error */\;
            $q'_i = |L_i ~\cup~ L'_i|(1-\frac{2(e_i~+~e'_i)}{|L_i ~\cup~ L'_i|})^2$\;

            \If{$q'_i > q_i$}{
                $L_i = L_i ~\cup~ L'_i$\;
                $e_i = e_i~+~e'_i$\;
            }
        }
        
     }
     \Return{Combinar($\pmb{H}_1,\pmb{H}_2,...,\pmb{H}_n$)}
     \caption{Democratic Co-Learning --- entrenamiento}\label{pseudo:democraticco-learning}
\end{algorithm}

\begin{algorithm}
    \DontPrintSemicolon
    \KwIn{$\pmb{H}_1,\pmb{H}_2,...,\pmb{H}_n$ y $\mathbf{x}$ (instancia)}
    \KwOut{Hipótesis combinadas (predicción)}
    \For{i = 1,...,n}{
        Utilizar $\pmb{L}$ para calcular el intervalo de confianza al 95\%, [$l_i$,~$h_i$] de $\pmb{H}_i$\;
            $w_i = (l_i + h_i)/2$\;
    }
    \For{i = 1,...,n}{
        \If{$H_i(\mathbf{x})$ predice $c_j$ ~y ~$w_i >$ 0.5}{
            Añadir $H_i$ al grupo $G_j$ /* $j$ es etiqueta */\;
        }
    }
    
    \For{j = 1,...,r}{
        $\bar{C}_{G_j} = \frac{|G_j|+0.5}{|G_j|+1} * \frac{\sum_{H_i \in G_j} w_i}{|G_j|}$
    }
    $H$ predice con el grupo $G_k$ con $k = \arg \max_j(\bar{C}_{G_j})$\;
    \textbf{return} $H$
    \caption{Democratic Co-Learning --- predicción (combinación)}\label{pseudo:combinar}
\end{algorithm}

Aclaración sobre la predicción final (en combinación): una vez calculadas las
confianzas de la instancia a predecir ($\mathbf{x}$) y por cada posible etiqueta, la idea
de la combinación es obtener la etiqueta ($k$, posición en el grupo) con mayor
confianza.

\clearpage
\clearpage

\section{Tri-Training}

En Co-Training, los algoritmos son entrenados con el conjunto de datos
etiquetados para luego ser reentrenados con los datos no etiquetados que han
pasado a estarlo.

En~\cite{1512038} (Tri-Training), Zhi-Hua Zhou y Ming Li, comentan la idea de
que para determinar qué ejemplo no etiquetado debe seleccionarse (para
etiquetar) y qué clasificador debe tener más influencia, se debe calcular la
\textit{confianza de etiquetado} de cada uno de los clasificadores. Sin embargo, esto
puede ser muy costoso de calcular.

En este caso, se tendrán tres clasificadores base. La idea es que, en línea de
lo anterior, para que un clasificador etiquete un ejemplo sin etiquetar, los
otros dos clasificadores deben coincidir en la etiqueta de ese ejemplo. Aunque
no es necesario calcular esa \textit{confianza de etiquetado} de cada
clasificador en particular.

Una consecuencia de lo anterior es que, si los otros dos clasificadores fallan
en su predicción (y coinciden), se añadirá esa etiqueta y se estaría
introduciendo un ejemplo mal etiquetado. Sin embargo, en el peor caso, el ruido
introducido puede ser compensado si hay suficientes datos nuevos etiquetados
(bajo ciertas condiciones~\cite{1512038}).

Una particularidad de Tri-Training es que tanto la cantidad como los ejemplos
concretos no etiquetados que son seleccionados para ser etiquetados no será
siempre el mismo en cada iteración. Para comprender esto, cada uno de los
clasificadores tiene, aparte del conjunto de entrada etiquetado $L$, un conjunto
con los datos recién etiquetados en cada iteración $L_i$\footnote{Constituido
por esos ejemplos en los que los otros dos clasificadores determinan la misma
etiqueta}. Y de hecho, este conjunto es <<vaciado>> entre una iteración y otra.
Es utilizado para reentrenar al clasificador al final de la iteración uniendo
$L$ y $L_i$.

\paragraph{Proceso general}

El primer paso es entrenar a cada uno de los tres clasificadores ($h_i$, $h_j$ y
$h_k$) mediante una muestra aleatoria del conjunto de entrada $L$.

A continuación, el algoritmo entra en un bucle cuya condición de parada es que
ningún clasificador obtenga nuevos ejemplos para entrenar (ejemplos que eran no
etiquetados). 

Dentro del bucle y suponiendo la perspectiva del clasificador $i$ lo primero que
se hace es <<vaciar>> el conjunto de datos seleccionados para él, $L_i$. En
segundo lugar, se realiza una estimación del error de la combinación de las
hipótesis $h_j$ y $h_k$\footnote{El error de clasificación se aproxima
dividiendo el número de instancias (de entrenamiento) en las que $h_j$ y $h_k$
se equivocan entre el número de instancias en las que predicen la misma etiqueta
~\cite{1512038}.}. Si el error no es menor que el de la iteración anterior $e_i$,
se vuelve al inicio del bucle.

Si el error sí era menor, el conjunto $L_i$ es rellenado con aquellos ejemplos
del conjunto de no etiquetados $U$ en los que $h_j$ y $h_k$ predicen la misma
etiqueta.

A partir de aquí, se realizan comprobaciones sobre ecuaciones del ratio de ruido
y errores~\cite{1512038} que determinarán si los ejemplos realmente serán
utilizados para reentrenar. De hecho, es posible también que el conjunto $L_i$
sea reducido.

Al final del bucle si las comprobaciones realizadas determinaron que $L_i$
contiene ejemplos de interés para $h_i$, dicho clasificador es entrenado con la
unión de $L$ y $L_i$.

\paragraph{Predicción}

La predicción de una nueva instancia es un proceso sencillo. Cada uno de los
clasificadores $h_i$, $h_j$ y $h_k$ predicen la etiqueta de esta nueva instancia
y se retorna la mayoritaria.

\begin{algorithm}
    \DontPrintSemicolon
    \KwIn{Conjunto de datos etiquetados $\pmb{L}$, 
    no etiquetados $\pmb{U}$ y algoritmo de aprendizaje \textit{Learn}
    }
    \For{$i \in \{1..3\}$}{
        $S_i \leftarrow BootstrapSample(L)$\;
        $h_i \leftarrow Learn(S_i)$\;
        $h_i \leftarrow .5$; $l'_i \leftarrow 0$\;
     }
     \Repeat{ningún $h_i~(i \in \{1..3\})$ cambie}{
        \For{$i \in \{1..3\}$}{
            $L_i \leftarrow \emptyset$\;
            $update_i \leftarrow False$\;
            $e_i \leftarrow MeasureError(h_j \& h_k)~(j, k \neq i)$\;
            \If{$e_i < e'_i$}{
                \For{every $x \in U$}{
                    \If{$h_j~(x) = h_k~(x)~(j,k \neq i)$}{
                        $L_i \leftarrow L_i \cup \{(x, h_j~(x))\}$
                    }
                }
                \If{$l'_i = 0$  /* $h_i$ no ha sido actualizado antes */}{
                    $l'_i \leftarrow \lfloor\frac{e_i}{e'_i - e_i} + 1 \rfloor$
                }
                \If{$l'_i < |L_i|$}{
                    \If{$e_i|L_i|< e'_i l'_i$}{
                        $update_i \leftarrow True$
                    }\ElseIf{$l'_i > \frac{e_i}{e'_i - e_i}$}{
                        $L_i \leftarrow Subsample(L_i, \lceil\frac{e'_il'_i}{e_i} - 1\rceil)$\;
                        $update_i \leftarrow True$
                    }
                }
            }
        }

        \For{$i \in \{1..3\}$}{
            \If{$update_i = True$}{
                $h_i \leftarrow Learn(L \cup L_i); e'_i \leftarrow e_i; l'_i \leftarrow |L_i|$
            }
        }
     }
     \Return{$h(x) \leftarrow arg~max_{y \in label}  \sum_{i:h_i(x)=y} 1$}
     \caption{Tri-Training}\label{pseudo:tri-training}
\end{algorithm}
\clearpage

\section{Técnicas de tratamiento de datos}

En el proceso de minería de datos y aprendizaje automático una de las primeras
etapas, y principales, es el preprocesamiento de datos. Este concepto hace
referencia a la manipulación,  eliminación y/o transformación de datos antes de
ser usados para mejorar el rendimiento del proceso~\cite{enwiki:1138293751}.

El tratamiento de datos también es particularmente útil en el área de la
interpretación y la visualización de datos. En ocasiones, el conocimiento
obtenido es difícil de interpretar con reglas o puras matemáticas.

En esta sección se van a comentar algunos conceptos que se han aplicado en el
área de tratamiento de datos (tanto en la parte de preprocesamiento como
visualización).

\subsection{Codificación de variables categóricas}
Este es el único tratamiento que el proyecto tiene incluido dentro del
preprocesamiento de los datos (el usuario es el encargado de tratar el resto de
cuestiones). Además, solo se aplica al atributo de la clase.

Muchos algoritmos de aprendizaje automático no son capaces de trabajar con
variables categóricas (no numéricas). Además, la categorización está presente en
muchos conjuntos de datos, ya que son muy útiles para aportar significado (los
números serían más difíciles de entender). Debido a las limitaciones de los
algoritmos, estos valores categóricos deben ser codificados como unos valores
numéricos.

Una de las ideas más directas (y la aplicada en el proyecto) es la
<<Codificación de etiquetas>> (\textit{Label encoding}). Esta técnica
simplemente trata cada valor único de etiqueta\footnote{Entendiendo etiqueta
como un valor del atributo de clase, no de una característica.} como un valor
numérico también único.

\begin{table}[H]
    \centering
\begin{tabular}{l|c}
Etiquetas originales & Etiquetas codificadas \\ \hline
Amarillo             & 0                     \\
Rojo                 & 1                     \\
Verde                & 2                     \\
Amarillo             & 0                     \\
Azul                 & 3                    
\end{tabular}
\caption{Codificación de etiquetas}
\end{table}

Desde el punto de vista del algoritmo, no necesita tener esa información que
aportaba la categoría (y que a nosotros sí nos ayuda). Simplemente, con mantener
la misma codificación para cada etiqueta, es suficiente.

\subsection{PCA (\textit{Principal Component Analysis})} 

Desde el punto de vista de la interpretación de los datos, PCA puede ser muy
útil (también se utiliza en el preprocesamiento en algún proceso de minería).

El análisis de componentes principales es un algoritmo matemático que reduce la
dimensionalidad de los datos manteniendo la mayoría de las variaciones en los
datos. Esto lo realiza identificando componentes principales~
~\cite{ringner2008principal}. Una componente principal es una nueva variable que
es combinación lineal de las variables originales con la particularidad de que
esa combinación de variables mantiene la mayor cantidad de varianza del conjunto
de datos original. La idea es mantener los patrones escondidos en los datos, en
las componentes principales, para que, si se aplica a un proceso de minería de
datos, se pueda seguir extrayendo conocimiento.

Aplicar PCA permite utilizar solo unas pocas componentes que pueden ser
graficadas y hacer posible la visualización de diferencias y similitudes.

Esta idea es la que se ha usado para las visualizaciones del proyecto. En muchos
casos se tendrá una dimensionalidad alta y por lo tanto no se puede visualizar
en dos dimensiones.

\subsection{Estandarización}

La estandarización en el campo de tratamiento de datos hace referencia a la
transformación de los valores para centrarlos en una media y con una cierta
desviación estándar (típicamente media cero y desviación 1).

\begin{equation}
  z = (x - u) / s
\end{equation}

\noindent $z$ es el nuevo valor, $x$ el valor original, $u$ la media y $s$ la
desviación típica.

La estandarización es útil cuando no se quiere establecer un rango fijo  de
valores (como en la normalización), y además, los \textit{outliers} (en
castellano valores atípicos) no afectan demasiado, ya que se considera la media
de todos ellos.

En el proyecto, es una opción que se le da al usuario para mostrar los datos
finales, ya que permite mantener las relaciones entre los datos pero
compactándolos lo suficiente para una buena visualización.

\subsection{HTTP (Descripción general)}

Al ser una aplicación Web, este proyecto tiene alta relación con este protocolo.
En el resto del apartado se van a documentar los conceptos que se han utilizado
en el desarrollo.

\emph{Hypertext Transfer Protocol (HTTP)} o Protocolo de Transferencia de
Hipertexto es un protocolo de la capa de aplicación\footnote{Permite a las
aplicaciones trabajar con los servicios de las capas inferiores y define
protocolos para el intercambio de datos~\cite{eswiki:149372346}} para transmitir
documentos. Se trata de un modelo cliente-servidor clásico, el cliente realiza
una petición al servidor, y espera a que este le devuelva una respuesta
~\cite{http:mdn}.

\imagen{memoria/HTTP}{Diagrama cliente-servidor.}{0.8}


Características de HTTP~\cite{http:features}:
\begin{itemize}
	\item Protocolo sin conexión: esto significa que la comunicación antes
	comentada ocurre sin realizar un acuerdo previo entre el cliente y el
	servidor.
	\item Independiente al tipo de contenido: quiere decir que HTTP no limita
	los datos que se pueden enviar, siempre y cuando, tanto el cliente como el
	servidor sepan manejar esos datos.
	\item Protocolo sin estado: cliente y servidor solo saben de su existencia
	durante la comunicación, no retienen la información de peticiones
	anteriores.
\end{itemize}


\subsubsection{Estructura de las peticiones y respuestas}

La realidad es que, peticiones y respuestas, tienen una estructura muy similar. Para las peticiones:
\begin{itemize}
	\item \textbf{Línea de inicio}, formada por:
  \subitem El método HTTP (se describirán a continuación), indica la operación a realizar.
  \subitem El objetivo, generalmente una URL. Para algunos métodos, aquí ser
  incorporan también los parámetros de la petición (\texttt{?param=X}).
  \subitem Versión del protocolo.
	\item \textbf{Cabeceras}: Son <<metadatos>> que proporcionan información sobre la
  petición. Cada una de ellas (puede haber varias) es un par nombre-valor.	Por
  ejemplo, especificar el tipo de contenido de la petición se haría con
  <<\texttt{Content-Type: application/json}>>.
  \item \textbf{Cuerpo}: Contiene información adicional para el servidor, pudiendo enviar
  cualquier dato. No todas las peticiones llevan cuerpo, una petición GET no lo
  necesita, pero sí un POST.
\end{itemize}

Para las respuestas:
\begin{itemize}
	\item \textbf{Línea de estado}, formada por:
  \subitem Versión del protocolo.
  \subitem Código de estado que indican el estado de la petición (se describirán a continuación).
  \subitem Descripción textual del código de estado (para poder interpretarlo).
	\item \textbf{Cabeceras}: Del mismo modo que las peticiones, son <<metadatos>> que
  proporcionan información sobre la petición. Cada una de ellas (puede haber
  varias) es un par nombre-valor.
  \item \textbf{Cuerpo}: Para aquellas respuestas que tengan cuerpo (algunas no lo tienen),
  contiene los datos solicitados o generados por el servidor.
\end{itemize}

\lstdefinestyle{bash}
{
    backgroundcolor=\color{black},
    basicstyle=\scriptsize\color{white}\ttfamily
}
\lstset{escapeinside={<@}{@>}}

\begin{figure}[H]
\begin{lstlisting}[style=bash]
<@\textcolor{green}{acha@DESKTOP-9MJIVL5}@>:~$ curl -i https://vass.dmacha.dev
HTTP/1.1 200 OK
Server: nginx/1.18.0 (Ubuntu)
Date: Mon, 05 Jun 2023 13:56:02 GMT
Content-Type: text/html; charset=utf-8
Content-Length: 7453
Connection: keep-alive
Vary: Cookie

<!DOCTYPE html>
<html lang="es">
<head>
\end{lstlisting}
\caption{Ejemplo de respuesta con su estructura.}
\end{figure}

Como se ha visto en las operaciones HTTP, todas tienen un indicativo, llamado
método, que permite distinguir qué tipo de operación se quiere realizar. El
protocolo HTTP soporta una enorme cantidad de métodos, algunos de ellos son para
contextos muy específicos. Los más utilizados (constantemente en entornos
reales) son~\cite{enwiki:1151700575}:
\begin{itemize}
	\item \textbf{GET}: Solicitud de un recurso. Solo para recuperar datos, sin
  otras operaciones. Generalmente a la URL se le añaden parámetros que
  configuran esta solicitud para que el servidor pueda personalizar las
  respuestas.
  \item \textbf{POST}: Solicitud que envía datos en el cuerpo de la petición (es
  el método de los formularios HTML, por ejemplo). Tiene diversas funciones,
  como crear un recurso o actualizarlo. Sin embargo, pese a que no está pensado
  para ello, en muchas ocasiones, también se utiliza para solicitar información.
  
  Entre otras cosas, solicitar información con POST, permite reducir la longitud
  de las URLs para operaciones GET demasiado extensas (incluso que puedan
  sobrepasar el límite de caracteres) y también permite ocultar información
  comprometida~\cite{http:postnotget}. 
  
  Las peticiones GET son parametrizadas mediante la propia URL, mientras que en
  POST, los parámetros pueden incorporarse al cuerpo de la petición,
  ocultándolos (interesante, por ejemplo, si no se quiere compartir
  identificadores).
  \item \textbf{PUT}: Método similar a POST, también envía datos al servidor,
  pero en este caso está orientado específicamente a la actualización de los
  recursos.
  \item \textbf{DELETE}: Método para eliminar recursos.
\end{itemize}

Los códigos de estado antes mencionados son parte de la respuesta del servidor a
los clientes. Indicarán, por lo general, el éxito o fracaso de las operaciones.

Hay aproximadamente 60 códigos distintos, cada uno brinda la posibilidad de
personalizar las respuestas dependiendo del contexto. Todos estos códigos pueden
ir acompañados de la estructura antes comentada. Por ejemplo, para una petición
exitosa, la respuesta de un POST podría tener un \texttt{cuerpo} con más
información junto con el código \textit{200}. 

Los códigos más utilizados son:

\begin{itemize}
	\item \textbf{200}: \emph{OK}, respuesta a peticiones HTTP exitosas.
  \item \textbf{400}: \emph{Bad Request}, el servidor no puede procesar la petición
  debido a una petición mal construida.
  \item \textbf{401}: \emph{Unauthorized}, no se tiene las credenciales de
  autenticación válidas para acceder al recurso solicitado.
  \item \textbf{403}: \emph{Forbidden}, el servidor entiende la petición pero la
  rechaza.
  \item \textbf{404}: \emph{Not Found}, el recurso no puedo ser encontrado.
  \item \textbf{405}: \emph{Method Not Allowed}, el método no es soportado para acceder
  al recurso. Por ejemplo, utilizar un GET cuando está pensado para utilizarse
  un POST.
  \item \textbf{500}: \emph{Internal Server Error}, respuesta genérica para errores
  internos, sin mensaje específico de los mismos.
\end{itemize}

\paragraph{HTTP Cookies}

El concepto de las \textit{cookies} es sencillo, son pequeños bloques de datos
que el servidor manda al navegador del usuario mientras realiza peticiones HTTP
a él. Una vez que el cliente ha almacenado esta información, puede usarla para
agilizar ciertos pasos en las siguientes peticiones. Cuando vuelva a acceder,
junto con la petición <<normal>> enviará esta porción de datos, que el servidor
puede interpretar y reconocer. Por ejemplo, pueden guardarse los inicios de
sesión, preferencias o, en entornos comerciales, el comportamiento del usuario.

La idea interesante de las \textit{cookies} es que permite almacenar
\textbf{información de estado} para el protocolo HTTP, que es \textbf{sin
estado} (por sí solo no puede guardar esta información).

\section{CSRF (Cross-Site Request Forgery)}
\emph{Cross-Site Request Forgery} (falsificación de petición en sitios cruzados)
es un ataque sobre aplicaciones web vulnerables en las que se utiliza a un
usuario autenticado en la misma (o en el que la web confía) para enviar una
petición maliciosa. Los ataques CSRF explotan la confianza que una web tiene con
un usuario, al no poder diferenciar entre una petición generada por el usuario
(la persona) y la petición generada por el usuario, pero sin su consentimiento
~\cite{csrf} (generalmente de forma cruzada, proveniente de otro contexto).

Se presenta un ejemplo explicativo:

\begin{tcolorbox}[colback=cyan!5!white,colframe=cyan!75!black,title=Situación]
Web vulnerable: \url{https://ejemplo.es}

Usuario: David (con sesión iniciada)

URL de cambio de contraseña: \url{https://ejemplo.es/cambiarcontrasena} (permite
un parámetro <<nueva>> mediante POST para especificar la nueva contraseña)

El servidor ha <<securizado>> parcialmente la URL anterior comprobando que el
que accede a esa URL es el propio usuario con sesión iniciada.
\end{tcolorbox}


\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Atacante]
    \begin{enumerate}
        \item Ha hecho ingeniería social para saber el Email de David:
        \mbox{\texttt{david@ejemplo.es}}.
        \item Envía un correo electrónico con un enlace que parece de Google.
        \item En realidad, todos los botones de esa página envían un formulario (POST)
        hacia \url{https://ejemplo.es/cambiarcontrasena}.
        \item El formulario tiene un campo oculto:
        \mint{html}|<input type="hidden" name="nueva" value="hackeado"/>|
    \end{enumerate}
\end{tcolorbox}

\begin{tcolorbox}[colback=green!5!white,colframe=green!75!black,title=David]
    \begin{enumerate}
        \item Recibe el correo en su bandeja de entrada.
        \item No se percata de que no es la página original de Google y entra en ella.
        \item Busca información en Google y pincha en un botón.
        \item Se realiza la petición POST a la aplicación web vulnerable en la que ha iniciado sesión.
        \item El servidor procesa la petición pues cree que es el propio usuario el que ha
        construido la petición conscientemente.
        \item La contraseña ha cambiado a <<hackeado>>.
    \end{enumerate}
\end{tcolorbox}

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Atacante]

Con el Email \texttt{david@ejemplo.es} y la contraseña \texttt{hackeado}, accede
a la Web \texttt{ejemplo.es} como si fuera David.

\end{tcolorbox}

\paragraph{Solución} Dada la vulnerabilidad comentada anteriormente, la solución
pasa por idear una forma de saber que esa petición se ha creado desde la propia
aplicación (no por terceros). Por lo tanto, la idea más efectiva es la creación
de un \emph{CSRF token} único para los usuarios, que el servidor
(aplicación) genera y <<guarda>> en la sesión de los mismos. Este <<token>> es
incrustado como un parámetro oculto en las peticiones (en los formularios) y al
realizar el envío del formulario, el servidor comprobará que el <<token>>
recibido era el correcto para el usuario.

